{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked Denoising AutoEncoder\n",
    "\n",
    "1. Input Layer : Energy, Contrast, Entropy, Homogeneity, SumAverage, Dissimilarity, AutoCorrelation, Skewness, Kurtosis, Average HU Value\n",
    "2. Feature 1 : 7\n",
    "3. Feature 2 : 3\n",
    "4. Softmax : 2\n",
    "5. Learning rate : .1 ~ .01\n",
    "6. Noise factor : 10% on input vector\n",
    "7. Activation function : sigmoid\n",
    "8. Cost function : negative log-likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three models\n",
    "1. Feature Extraction : Input -> HL1 -> HL2 -> Decoder -> Weight update\n",
    "2. Predict Features : Input -> HL1 -> HL2 -> Output\n",
    "3. Classification : Input of 3 -> HL1 -> HL2 -> Classifier -> Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras import optimizers, regularizers\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Function for cross validation\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26910, 11) \n",
      "Dataset loading complete\n"
     ]
    }
   ],
   "source": [
    "# Preparing dataset - total 27039 images : 14294 nodules + 12745 non-nodules\n",
    "df = pd.read_csv('./Datas/nodules_all_190625.csv', index_col=0)\n",
    "# select seed to randomize - [0, 3136, 8405, 4242, 5293]\n",
    "np.random.seed(0)\n",
    "print(df.shape, '\\nDataset loading complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice the inputs and labels\n",
    "# iloc : use integer index for slice\n",
    "# loc : use label for slice\n",
    "cols = df.shape[1] - 1\n",
    "x_train = df.iloc[:, :cols] \n",
    "y_train = df.iloc[:, cols]\n",
    "y_labels_train = to_categorical(y_train)\n",
    "\n",
    "# add noise to the input data\n",
    "noise_factor = 0.1\n",
    "x_train_noisy = x_train * (1 + noise_factor *\\\n",
    "            np.random.binomial(n=1, p=0.1, size=x_train.shape) )\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build Autoencoder\n",
    "# Input placeholder\n",
    "input_data = Input(shape=(cols,))\n",
    "\n",
    "# Hidden Layer 1\n",
    "hidden_1 = Dense(8, activation='tanh', kernel_initializer='he_normal',\n",
    "                    )(input_data)\n",
    "\n",
    "# Hidden Layer 2\n",
    "hidden_2 = Dense(6, activation='tanh', kernel_initializer='he_normal',\n",
    "                    )(hidden_1)\n",
    "\n",
    "# Decoded Layer 1\n",
    "decoded_1 = Dense(8, activation='sigmoid', kernel_initializer='he_normal')(hidden_2)\n",
    "\n",
    "# Decoded Layer 2 (reconstructed data)\n",
    "decoded_2 = Dense(cols, activation='sigmoid', kernel_initializer='he_normal')(decoded_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 8)                 88        \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 8)                 56        \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 10)                90        \n",
      "=================================================================\n",
      "Total params: 288\n",
      "Trainable params: 288\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# this model maps an input to its reconstruction\n",
    "from keras import optimizers\n",
    "\n",
    "autoencoder_recon = Model(input_data, decoded_2)\n",
    "ada = optimizers.Adadelta(decay=0)\n",
    "sgd = optimizers.SGD(lr=0.01)\n",
    "autoencoder_recon.compile(optimizer=ada, loss='binary_crossentropy')\n",
    "autoencoder_recon.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25564 samples, validate on 1346 samples\n",
      "Epoch 1/100\n",
      "25564/25564 [==============================] - 2s 66us/step - loss: 0.8136 - val_loss: 0.6570\n",
      "Epoch 2/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.5891 - val_loss: 0.5567\n",
      "Epoch 3/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.5259 - val_loss: 0.5190\n",
      "Epoch 4/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4979 - val_loss: 0.5001\n",
      "Epoch 5/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4828 - val_loss: 0.4895\n",
      "Epoch 6/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4741 - val_loss: 0.4835\n",
      "Epoch 7/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4688 - val_loss: 0.4804\n",
      "Epoch 8/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4656 - val_loss: 0.4786\n",
      "Epoch 9/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4638 - val_loss: 0.4779\n",
      "Epoch 10/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4628 - val_loss: 0.4778\n",
      "Epoch 11/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4624 - val_loss: 0.4777\n",
      "Epoch 12/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4621 - val_loss: 0.4777\n",
      "Epoch 13/100\n",
      "25564/25564 [==============================] - 0s 12us/step - loss: 0.4620 - val_loss: 0.4779\n",
      "Epoch 14/100\n",
      "25564/25564 [==============================] - 0s 12us/step - loss: 0.4620 - val_loss: 0.4779\n",
      "Epoch 15/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4620 - val_loss: 0.4779\n",
      "Epoch 16/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4620 - val_loss: 0.4779\n",
      "Epoch 17/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4620 - val_loss: 0.4779\n",
      "Epoch 18/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4620 - val_loss: 0.4779\n",
      "Epoch 19/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4620 - val_loss: 0.4780\n",
      "Epoch 20/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4620 - val_loss: 0.4779\n",
      "Epoch 21/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4620 - val_loss: 0.4779\n",
      "Epoch 22/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4620 - val_loss: 0.4778\n",
      "Epoch 23/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4620 - val_loss: 0.4779\n",
      "Epoch 24/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4620 - val_loss: 0.4778\n",
      "Epoch 25/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4620 - val_loss: 0.4780\n",
      "Epoch 26/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4620 - val_loss: 0.4780\n",
      "Epoch 27/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4620 - val_loss: 0.4777\n",
      "Epoch 28/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4620 - val_loss: 0.4779\n",
      "Epoch 29/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4620 - val_loss: 0.4777\n",
      "Epoch 30/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4620 - val_loss: 0.4777\n",
      "Epoch 31/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4620 - val_loss: 0.4777\n",
      "Epoch 32/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4620 - val_loss: 0.4778\n",
      "Epoch 33/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4620 - val_loss: 0.4779\n",
      "Epoch 34/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4620 - val_loss: 0.4778\n",
      "Epoch 35/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4620 - val_loss: 0.4779\n",
      "Epoch 36/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4620 - val_loss: 0.4778\n",
      "Epoch 37/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4620 - val_loss: 0.4777\n",
      "Epoch 38/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4620 - val_loss: 0.4778\n",
      "Epoch 39/100\n",
      "25564/25564 [==============================] - 0s 12us/step - loss: 0.4620 - val_loss: 0.4779\n",
      "Epoch 40/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4620 - val_loss: 0.4778\n",
      "Epoch 41/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4620 - val_loss: 0.4777\n",
      "Epoch 42/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4619 - val_loss: 0.4778\n",
      "Epoch 43/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4619 - val_loss: 0.4779\n",
      "Epoch 44/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4619 - val_loss: 0.4778\n",
      "Epoch 45/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4619 - val_loss: 0.4778\n",
      "Epoch 46/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4619 - val_loss: 0.4779\n",
      "Epoch 47/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4619 - val_loss: 0.4778\n",
      "Epoch 48/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4619 - val_loss: 0.4777\n",
      "Epoch 49/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4619 - val_loss: 0.4777\n",
      "Epoch 50/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4619 - val_loss: 0.4776\n",
      "Epoch 51/100\n",
      "25564/25564 [==============================] - 0s 12us/step - loss: 0.4618 - val_loss: 0.4777\n",
      "Epoch 52/100\n",
      "25564/25564 [==============================] - 0s 12us/step - loss: 0.4618 - val_loss: 0.4775\n",
      "Epoch 53/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4617 - val_loss: 0.4773\n",
      "Epoch 54/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4613 - val_loss: 0.4767\n",
      "Epoch 55/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4606 - val_loss: 0.4754\n",
      "Epoch 56/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4592 - val_loss: 0.4732\n",
      "Epoch 57/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4568 - val_loss: 0.4694\n",
      "Epoch 58/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4530 - val_loss: 0.4638\n",
      "Epoch 59/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4488 - val_loss: 0.4589\n",
      "Epoch 60/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4458 - val_loss: 0.4559\n",
      "Epoch 61/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4439 - val_loss: 0.4540\n",
      "Epoch 62/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4428 - val_loss: 0.4525\n",
      "Epoch 63/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4421 - val_loss: 0.4516\n",
      "Epoch 64/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4416 - val_loss: 0.4510\n",
      "Epoch 65/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4412 - val_loss: 0.4505\n",
      "Epoch 66/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4409 - val_loss: 0.4501\n",
      "Epoch 67/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4407 - val_loss: 0.4497\n",
      "Epoch 68/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4405 - val_loss: 0.4494\n",
      "Epoch 69/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4403 - val_loss: 0.4491\n",
      "Epoch 70/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4401 - val_loss: 0.4489\n",
      "Epoch 71/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4400 - val_loss: 0.4485\n",
      "Epoch 72/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4398 - val_loss: 0.4483\n",
      "Epoch 73/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4397 - val_loss: 0.4481\n",
      "Epoch 74/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4396 - val_loss: 0.4479\n",
      "Epoch 75/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4395 - val_loss: 0.4477\n",
      "Epoch 76/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4394 - val_loss: 0.4473\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4393 - val_loss: 0.4471\n",
      "Epoch 78/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4392 - val_loss: 0.4470\n",
      "Epoch 79/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4391 - val_loss: 0.4467\n",
      "Epoch 80/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4390 - val_loss: 0.4465\n",
      "Epoch 81/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4389 - val_loss: 0.4463\n",
      "Epoch 82/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4388 - val_loss: 0.4462\n",
      "Epoch 83/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4387 - val_loss: 0.4458\n",
      "Epoch 84/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4386 - val_loss: 0.4456\n",
      "Epoch 85/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4385 - val_loss: 0.4454\n",
      "Epoch 86/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4383 - val_loss: 0.4451\n",
      "Epoch 87/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4382 - val_loss: 0.4448\n",
      "Epoch 88/100\n",
      "25564/25564 [==============================] - 0s 12us/step - loss: 0.4380 - val_loss: 0.4445\n",
      "Epoch 89/100\n",
      "25564/25564 [==============================] - 0s 12us/step - loss: 0.4378 - val_loss: 0.4441\n",
      "Epoch 90/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4375 - val_loss: 0.4432\n",
      "Epoch 91/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4367 - val_loss: 0.4418\n",
      "Epoch 92/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4352 - val_loss: 0.4398\n",
      "Epoch 93/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4336 - val_loss: 0.4382\n",
      "Epoch 94/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4322 - val_loss: 0.4368\n",
      "Epoch 95/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4313 - val_loss: 0.4358\n",
      "Epoch 96/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4306 - val_loss: 0.4351\n",
      "Epoch 97/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4301 - val_loss: 0.4345\n",
      "Epoch 98/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4297 - val_loss: 0.4341\n",
      "Epoch 99/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4294 - val_loss: 0.4337\n",
      "Epoch 100/100\n",
      "25564/25564 [==============================] - 0s 11us/step - loss: 0.4292 - val_loss: 0.4334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa01c968f28>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder_recon.fit(x_train_noisy, x_train,\n",
    "                      epochs=100, batch_size=256,\n",
    "                      validation_split=0.05,\n",
    "                      verbose=1,\n",
    "                      shuffle=True,\n",
    "                      # callbacks=[TensorBoard(log_dir='./logs/autoencoder_190601-5')]\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21528/21528 [==============================] - 1s 61us/step - loss: 0.7137 - acc: 0.5321\n",
      "Epoch 2/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.6613 - acc: 0.6098\n",
      "Epoch 3/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.6260 - acc: 0.6570\n",
      "Epoch 4/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.6026 - acc: 0.6843\n",
      "Epoch 5/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5876 - acc: 0.7021\n",
      "Epoch 6/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5783 - acc: 0.7081\n",
      "Epoch 7/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5728 - acc: 0.7135\n",
      "Epoch 8/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5697 - acc: 0.7141\n",
      "Epoch 9/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5680 - acc: 0.7149\n",
      "Epoch 10/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5669 - acc: 0.7153\n",
      "Epoch 11/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5660 - acc: 0.7164\n",
      "Epoch 12/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5652 - acc: 0.7168\n",
      "Epoch 13/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5644 - acc: 0.7175\n",
      "Epoch 14/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5637 - acc: 0.7185\n",
      "Epoch 15/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5629 - acc: 0.7183\n",
      "Epoch 16/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5623 - acc: 0.7199\n",
      "Epoch 17/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5616 - acc: 0.7204\n",
      "Epoch 18/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5609 - acc: 0.7210\n",
      "Epoch 19/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5602 - acc: 0.7213\n",
      "Epoch 20/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5594 - acc: 0.7225\n",
      "Epoch 21/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5587 - acc: 0.7232\n",
      "Epoch 22/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5580 - acc: 0.7235\n",
      "Epoch 23/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5573 - acc: 0.7244\n",
      "Epoch 24/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5567 - acc: 0.7247\n",
      "Epoch 25/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5560 - acc: 0.7249\n",
      "Epoch 26/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5553 - acc: 0.7262\n",
      "Epoch 27/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5546 - acc: 0.7275\n",
      "Epoch 28/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5540 - acc: 0.7275\n",
      "Epoch 29/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5533 - acc: 0.7282\n",
      "Epoch 30/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5525 - acc: 0.7303\n",
      "Epoch 31/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5520 - acc: 0.7290\n",
      "Epoch 32/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5514 - acc: 0.7308\n",
      "Epoch 33/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5508 - acc: 0.7314\n",
      "Epoch 34/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5502 - acc: 0.7332\n",
      "Epoch 35/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5497 - acc: 0.7323\n",
      "Epoch 36/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5492 - acc: 0.7336\n",
      "Epoch 37/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5486 - acc: 0.7341\n",
      "Epoch 38/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5481 - acc: 0.7349\n",
      "Epoch 39/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5474 - acc: 0.7359\n",
      "Epoch 40/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5469 - acc: 0.7364\n",
      "Epoch 41/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5463 - acc: 0.7368\n",
      "Epoch 42/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5458 - acc: 0.7375\n",
      "Epoch 43/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5453 - acc: 0.7386\n",
      "Epoch 44/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5448 - acc: 0.7386\n",
      "Epoch 45/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5443 - acc: 0.7385\n",
      "Epoch 46/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5438 - acc: 0.7398\n",
      "Epoch 47/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5433 - acc: 0.7391\n",
      "Epoch 48/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5428 - acc: 0.7405\n",
      "Epoch 49/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5423 - acc: 0.7408\n",
      "Epoch 50/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5419 - acc: 0.7414\n",
      "Epoch 1/50\n",
      "21528/21528 [==============================] - 1s 62us/step - loss: 0.6656 - acc: 0.6149\n",
      "Epoch 2/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.6440 - acc: 0.6329\n",
      "Epoch 3/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.6281 - acc: 0.6476\n",
      "Epoch 4/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.6148 - acc: 0.6647\n",
      "Epoch 5/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.6040 - acc: 0.6764\n",
      "Epoch 6/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5955 - acc: 0.6860\n",
      "Epoch 7/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5889 - acc: 0.6924\n",
      "Epoch 8/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5839 - acc: 0.6984\n",
      "Epoch 9/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5801 - acc: 0.7035\n",
      "Epoch 10/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5774 - acc: 0.7068\n",
      "Epoch 11/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5751 - acc: 0.7074\n",
      "Epoch 12/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5735 - acc: 0.7090\n",
      "Epoch 13/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5721 - acc: 0.7107\n",
      "Epoch 14/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5709 - acc: 0.7110\n",
      "Epoch 15/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5699 - acc: 0.7118\n",
      "Epoch 16/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5689 - acc: 0.7135\n",
      "Epoch 17/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5680 - acc: 0.7140\n",
      "Epoch 18/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5671 - acc: 0.7142\n",
      "Epoch 19/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5662 - acc: 0.7161\n",
      "Epoch 20/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5652 - acc: 0.7165\n",
      "Epoch 21/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5644 - acc: 0.7173\n",
      "Epoch 22/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5636 - acc: 0.7178\n",
      "Epoch 23/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5628 - acc: 0.7195\n",
      "Epoch 24/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5621 - acc: 0.7198\n",
      "Epoch 25/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5614 - acc: 0.7192\n",
      "Epoch 26/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5607 - acc: 0.7203\n",
      "Epoch 27/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5599 - acc: 0.7214\n",
      "Epoch 28/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5591 - acc: 0.7214\n",
      "Epoch 29/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5583 - acc: 0.7233\n",
      "Epoch 30/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5575 - acc: 0.7230\n",
      "Epoch 31/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5567 - acc: 0.7242\n",
      "Epoch 32/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5560 - acc: 0.7245\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21528/21528 [==============================] - 0s 6us/step - loss: 0.5553 - acc: 0.7254\n",
      "Epoch 34/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5546 - acc: 0.7260\n",
      "Epoch 35/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5539 - acc: 0.7260\n",
      "Epoch 36/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5532 - acc: 0.7274\n",
      "Epoch 37/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5527 - acc: 0.7280\n",
      "Epoch 38/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5520 - acc: 0.7288\n",
      "Epoch 39/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5514 - acc: 0.7294\n",
      "Epoch 40/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5508 - acc: 0.7295\n",
      "Epoch 41/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5502 - acc: 0.7307\n",
      "Epoch 42/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5495 - acc: 0.7315\n",
      "Epoch 43/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5489 - acc: 0.7318\n",
      "Epoch 44/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5483 - acc: 0.7324\n",
      "Epoch 45/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5477 - acc: 0.7330\n",
      "Epoch 46/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5470 - acc: 0.7348\n",
      "Epoch 47/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5464 - acc: 0.7343\n",
      "Epoch 48/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5458 - acc: 0.7350\n",
      "Epoch 49/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5452 - acc: 0.7363\n",
      "Epoch 50/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5447 - acc: 0.7363\n",
      "Epoch 1/50\n",
      "21528/21528 [==============================] - 1s 63us/step - loss: 0.8106 - acc: 0.4722\n",
      "Epoch 2/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.6613 - acc: 0.5942\n",
      "Epoch 3/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.6056 - acc: 0.6930\n",
      "Epoch 4/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5889 - acc: 0.7029\n",
      "Epoch 5/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5839 - acc: 0.7006\n",
      "Epoch 6/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5815 - acc: 0.7013\n",
      "Epoch 7/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5799 - acc: 0.7021\n",
      "Epoch 8/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5787 - acc: 0.7037\n",
      "Epoch 9/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5776 - acc: 0.7048\n",
      "Epoch 10/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5767 - acc: 0.7056\n",
      "Epoch 11/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5758 - acc: 0.7061\n",
      "Epoch 12/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5749 - acc: 0.7069\n",
      "Epoch 13/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5741 - acc: 0.7080\n",
      "Epoch 14/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5734 - acc: 0.7088\n",
      "Epoch 15/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5727 - acc: 0.7096\n",
      "Epoch 16/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5718 - acc: 0.7100\n",
      "Epoch 17/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5710 - acc: 0.7110\n",
      "Epoch 18/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5701 - acc: 0.7119\n",
      "Epoch 19/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5692 - acc: 0.7123\n",
      "Epoch 20/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5684 - acc: 0.7144\n",
      "Epoch 21/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5676 - acc: 0.7147\n",
      "Epoch 22/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5670 - acc: 0.7152\n",
      "Epoch 23/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5663 - acc: 0.7159\n",
      "Epoch 24/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5656 - acc: 0.7168\n",
      "Epoch 25/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5648 - acc: 0.7171\n",
      "Epoch 26/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5640 - acc: 0.7184\n",
      "Epoch 27/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5632 - acc: 0.7183\n",
      "Epoch 28/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5624 - acc: 0.7190\n",
      "Epoch 29/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5616 - acc: 0.7203\n",
      "Epoch 30/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5609 - acc: 0.7208\n",
      "Epoch 31/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5602 - acc: 0.7210\n",
      "Epoch 32/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5595 - acc: 0.7225\n",
      "Epoch 33/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5588 - acc: 0.7228\n",
      "Epoch 34/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5581 - acc: 0.7233\n",
      "Epoch 35/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5575 - acc: 0.7248\n",
      "Epoch 36/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5567 - acc: 0.7258\n",
      "Epoch 37/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5561 - acc: 0.7261\n",
      "Epoch 38/50\n",
      "21528/21528 [==============================] - 0s 6us/step - loss: 0.5554 - acc: 0.7270\n",
      "Epoch 39/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5547 - acc: 0.7277\n",
      "Epoch 40/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5540 - acc: 0.7281\n",
      "Epoch 41/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5534 - acc: 0.7297\n",
      "Epoch 42/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5528 - acc: 0.7305\n",
      "Epoch 43/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5523 - acc: 0.7307\n",
      "Epoch 44/50\n",
      "21528/21528 [==============================] - 0s 6us/step - loss: 0.5518 - acc: 0.7311\n",
      "Epoch 45/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5513 - acc: 0.7321\n",
      "Epoch 46/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5508 - acc: 0.7324\n",
      "Epoch 47/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5501 - acc: 0.7334\n",
      "Epoch 48/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5496 - acc: 0.7326\n",
      "Epoch 49/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5491 - acc: 0.7343\n",
      "Epoch 50/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5485 - acc: 0.7348\n",
      "Epoch 1/50\n",
      "21528/21528 [==============================] - 1s 64us/step - loss: 0.7135 - acc: 0.5885\n",
      "Epoch 2/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.6829 - acc: 0.6079\n",
      "Epoch 3/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.6598 - acc: 0.6232\n",
      "Epoch 4/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.6404 - acc: 0.6398\n",
      "Epoch 5/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.6245 - acc: 0.6546\n",
      "Epoch 6/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.6112 - acc: 0.6675\n",
      "Epoch 7/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.6006 - acc: 0.6786\n",
      "Epoch 8/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5923 - acc: 0.6876\n",
      "Epoch 9/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5856 - acc: 0.6942\n",
      "Epoch 10/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5806 - acc: 0.7006\n",
      "Epoch 11/50\n",
      "21528/21528 [==============================] - 0s 6us/step - loss: 0.5769 - acc: 0.7047\n",
      "Epoch 12/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5741 - acc: 0.7074\n",
      "Epoch 13/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5720 - acc: 0.7080\n",
      "Epoch 14/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5704 - acc: 0.7102\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5691 - acc: 0.7110\n",
      "Epoch 16/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5681 - acc: 0.7118\n",
      "Epoch 17/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5670 - acc: 0.7134\n",
      "Epoch 18/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5661 - acc: 0.7143\n",
      "Epoch 19/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5652 - acc: 0.7144\n",
      "Epoch 20/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5644 - acc: 0.7150\n",
      "Epoch 21/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5635 - acc: 0.7160\n",
      "Epoch 22/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5627 - acc: 0.7170\n",
      "Epoch 23/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5619 - acc: 0.7181\n",
      "Epoch 24/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5612 - acc: 0.7186\n",
      "Epoch 25/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5605 - acc: 0.7188\n",
      "Epoch 26/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5598 - acc: 0.7200\n",
      "Epoch 27/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5590 - acc: 0.7204\n",
      "Epoch 28/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5583 - acc: 0.7212\n",
      "Epoch 29/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5575 - acc: 0.7217\n",
      "Epoch 30/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5569 - acc: 0.7219\n",
      "Epoch 31/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5563 - acc: 0.7234\n",
      "Epoch 32/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5557 - acc: 0.7238\n",
      "Epoch 33/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5550 - acc: 0.7244\n",
      "Epoch 34/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5544 - acc: 0.7246\n",
      "Epoch 35/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5538 - acc: 0.7254\n",
      "Epoch 36/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5532 - acc: 0.7261\n",
      "Epoch 37/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5525 - acc: 0.7271\n",
      "Epoch 38/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5519 - acc: 0.7283\n",
      "Epoch 39/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5512 - acc: 0.7282\n",
      "Epoch 40/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5507 - acc: 0.7290\n",
      "Epoch 41/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5501 - acc: 0.7302\n",
      "Epoch 42/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5495 - acc: 0.7300\n",
      "Epoch 43/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5491 - acc: 0.7309\n",
      "Epoch 44/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5485 - acc: 0.7312\n",
      "Epoch 45/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5479 - acc: 0.7321\n",
      "Epoch 46/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5473 - acc: 0.7324\n",
      "Epoch 47/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5467 - acc: 0.7327\n",
      "Epoch 48/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5461 - acc: 0.7339\n",
      "Epoch 49/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5456 - acc: 0.7350\n",
      "Epoch 50/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5451 - acc: 0.7354\n",
      "Epoch 1/50\n",
      "21528/21528 [==============================] - 1s 65us/step - loss: 0.7411 - acc: 0.5320\n",
      "Epoch 2/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.6442 - acc: 0.5922\n",
      "Epoch 3/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.6129 - acc: 0.6852\n",
      "Epoch 4/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5986 - acc: 0.6980\n",
      "Epoch 5/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5899 - acc: 0.7003\n",
      "Epoch 6/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5844 - acc: 0.7023\n",
      "Epoch 7/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5810 - acc: 0.7029\n",
      "Epoch 8/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5788 - acc: 0.7031\n",
      "Epoch 9/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5771 - acc: 0.7040\n",
      "Epoch 10/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5758 - acc: 0.7053\n",
      "Epoch 11/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5746 - acc: 0.7067\n",
      "Epoch 12/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5736 - acc: 0.7073\n",
      "Epoch 13/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5726 - acc: 0.7083\n",
      "Epoch 14/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5716 - acc: 0.7093\n",
      "Epoch 15/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5706 - acc: 0.7101\n",
      "Epoch 16/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5696 - acc: 0.7120\n",
      "Epoch 17/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5686 - acc: 0.7130\n",
      "Epoch 18/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5677 - acc: 0.7131\n",
      "Epoch 19/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5668 - acc: 0.7138\n",
      "Epoch 20/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5659 - acc: 0.7157\n",
      "Epoch 21/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5650 - acc: 0.7157\n",
      "Epoch 22/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5641 - acc: 0.7165\n",
      "Epoch 23/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5634 - acc: 0.7177\n",
      "Epoch 24/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5626 - acc: 0.7185\n",
      "Epoch 25/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5617 - acc: 0.7199\n",
      "Epoch 26/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5610 - acc: 0.7199\n",
      "Epoch 27/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5602 - acc: 0.7212\n",
      "Epoch 28/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5594 - acc: 0.7218\n",
      "Epoch 29/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5586 - acc: 0.7222\n",
      "Epoch 30/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5578 - acc: 0.7231\n",
      "Epoch 31/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5570 - acc: 0.7238\n",
      "Epoch 32/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5562 - acc: 0.7246\n",
      "Epoch 33/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5554 - acc: 0.7257\n",
      "Epoch 34/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5548 - acc: 0.7257\n",
      "Epoch 35/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5541 - acc: 0.7272\n",
      "Epoch 36/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5535 - acc: 0.7274\n",
      "Epoch 37/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5529 - acc: 0.7281\n",
      "Epoch 38/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5522 - acc: 0.7298\n",
      "Epoch 39/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5516 - acc: 0.7291\n",
      "Epoch 40/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5510 - acc: 0.7297\n",
      "Epoch 41/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5504 - acc: 0.7314\n",
      "Epoch 42/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5498 - acc: 0.7315\n",
      "Epoch 43/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5492 - acc: 0.7322\n",
      "Epoch 44/50\n",
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5486 - acc: 0.7323\n",
      "Epoch 45/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5480 - acc: 0.7336\n",
      "Epoch 46/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5475 - acc: 0.7332\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21528/21528 [==============================] - 0s 8us/step - loss: 0.5470 - acc: 0.7343\n",
      "Epoch 48/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5466 - acc: 0.7353\n",
      "Epoch 49/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5461 - acc: 0.7361\n",
      "Epoch 50/50\n",
      "21528/21528 [==============================] - 0s 7us/step - loss: 0.5458 - acc: 0.7359\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "\n",
    "# Encoder\n",
    "autoencoder_encoder = Model(input_data, hidden_2)\n",
    "\n",
    "def create_model(): \n",
    "    # create model \n",
    "    model = Sequential() \n",
    "    model.add(Dense(2, activation='softmax')) \n",
    "    # Compile model \n",
    "    model.compile(optimizer='adadelta', loss='categorical_crossentropy',\n",
    "                            metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "x_feature = autoencoder_encoder.predict(x_train)\n",
    "\n",
    "# Cross Validation\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, epochs=50, batch_size=256)\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "result = cross_validate(model, x_feature, y_train, verbose=0,\n",
    "                        scoring=['accuracy','precision','recall','f1','roc_auc'], \n",
    "                        cv=kfold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Sensitivity(True positive rate, TPR) or Recall\n",
    "$$ TPR=\\frac{TP}{TP+FN} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Precision(Positive predictive value, PPV)\n",
    "$$ PPV=\\frac{TP}{TP+FP} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73708658 0.72686734 0.74043107 0.73968785 0.74080268] \n",
      " Accuracy Average :  0.7369751021924935\n",
      "[0.8082379  0.79395119 0.81005568 0.80089125 0.80815232] \n",
      " ROC Average :  0.804257668348707\n",
      "[0.78739054 0.7813921  0.80264072 0.79168123 0.7819469 ] \n",
      " Recall Average :  0.7890102987526728\n",
      "[0.73560209 0.72556025 0.73590315 0.73778502 0.7392905 ] \n",
      " Precision Average :  0.7348282013092242\n",
      "[0.7606158  0.7524419  0.7678245  0.76378351 0.76002064] \n",
      " F-score Average :  0.7609372703381856\n"
     ]
    }
   ],
   "source": [
    "print(result['test_accuracy'], '\\n Accuracy Average : ', result['test_accuracy'].mean())\n",
    "print(result['test_roc_auc'], '\\n ROC Average : ', result['test_roc_auc'].mean())\n",
    "print(result['test_recall'], '\\n Recall Average : ', result['test_recall'].mean())\n",
    "print(result['test_precision'], '\\n Precision Average : ', result['test_precision'].mean())\n",
    "print(result['test_f1'], '\\n F-score Average : ', result['test_f1'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.03539762 0.03038412 0.13725859 ... 0.2112279  0.08401334 0.5017235 ]\n",
      " [0.03661236 0.03129858 0.1386151  ... 0.21433076 0.08619881 0.53268117]\n",
      " [0.04142064 0.0347321  0.14365745 ... 0.225766   0.09392393 0.61848646]\n",
      " ...\n",
      " [0.02695176 0.02376816 0.12559134 ... 0.18867755 0.06719133 0.22075084]\n",
      " [0.02653459 0.02353242 0.12515193 ... 0.18733719 0.06687602 0.22435096]\n",
      " [0.02631643 0.02332839 0.12464425 ... 0.18687914 0.06629669 0.2146121 ]]\n"
     ]
    }
   ],
   "source": [
    "decoded = autoencoder_recon.predict(x_train)\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Accuracy\n",
    "print(result, '\\n Average Accuracy : ', np.average(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Area under the ROC-curve (AUC)\n",
    "predicted = autoencoder_classify.predict(x_train)\n",
    "prediction_result = np.argmax(predicted, axis=1)\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_train.values, predicted[:, 1])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc_keras))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "TN, FP, FN, TP = confusion_matrix(y_train.values, prediction_result).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity = TP/(TP+FN)\n",
    "print('Sensitivity : ', sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = TP/(TP+FP)\n",
    "print('Precision : ', precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.F-score \n",
    "$$ \\text{F-score} = \\frac{(PPV \\times TPR)}{PPV+TPR} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_score = (precision * sensitivity) / (precision + sensitivity)\n",
    "print('F-score : ', f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(autoencoder_classify.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.768768  ,  0.88006055,  0.21781045, -0.0924427 , -0.00164266,\n",
       "          0.14979221],\n",
       "        [-0.5339661 ,  0.1496545 , -0.24011269, -0.32375374, -0.11565746,\n",
       "         -0.418027  ],\n",
       "        [-0.39518514, -0.31077665, -0.3810753 , -0.23387174, -0.5065482 ,\n",
       "         -0.08469566],\n",
       "        [-0.83951217, -0.34855592,  0.8481752 ,  0.13584559, -0.07653016,\n",
       "         -0.35563365],\n",
       "        [ 0.03268032, -0.10152446,  0.36609066,  0.48369616, -0.1670611 ,\n",
       "          0.59071624],\n",
       "        [-0.43042526,  0.06052483,  0.0949368 , -0.6796002 , -0.12490448,\n",
       "         -0.3713372 ],\n",
       "        [-0.04966786, -0.9637751 ,  0.12060661, -0.18130566,  0.28857023,\n",
       "         -0.49279264],\n",
       "        [-0.11784459, -0.94431806, -0.0221076 , -0.5024076 ,  0.08656775,\n",
       "         -0.360977  ],\n",
       "        [-0.13445432,  0.5711164 , -0.6203959 , -0.6823861 ,  0.07927413,\n",
       "          0.21285404],\n",
       "        [ 0.5014185 , -0.29338622, -0.78989136,  0.7650266 , -0.81578267,\n",
       "          0.3174904 ]], dtype=float32),\n",
       " array([ 0.00729265, -0.04263921,  0.00905127, -0.03471166, -0.03424358,\n",
       "        -0.03585815], dtype=float32)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder_recon.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_classify.layers[-1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "weight, bias = autoencoder_recon.layers[1].get_weights()\n",
    "\n",
    "plt.imshow(weight, cmap=plt.cm.autumn)\n",
    "plt.colorbar()\n",
    "plt.title('Weights Colormap - 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_avg = np.average(weight, axis=1)\n",
    "plt.plot(range(1,9), weight_avg)\n",
    "plt.title('Weights Average - 1')\n",
    "plt.xticks(range(1,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weight = pd.DataFrame(weight, \n",
    "                         columns=['Feature 1','Feature 2','Feature 3', 'Feature 4',\n",
    "                                 'Feature 5','Feature 6', 'Feature 7'])\n",
    "\n",
    "df_weight.to_csv(\"./Weights_sigmoid_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_all = autoencoder_recon.predict(x_train)\n",
    "print(decoded_all)\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
