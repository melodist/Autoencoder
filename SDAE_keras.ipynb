{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked Denoising AutoEncoder\n",
    "\n",
    "1. Input Layer : Energy, Contrast, Entropy, Homogeneity, SumAverage, Dissimilarity, AutoCorrelation, Skewness, Kurtosis, Average HU Value\n",
    "2. Feature 1 : 7\n",
    "3. Feature 2 : 3\n",
    "4. Softmax : 2\n",
    "5. Learning rate : .1 ~ .01\n",
    "6. Noise factor : 10% on input vector\n",
    "7. Activation function : sigmoid\n",
    "8. Cost function : negative log-likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three models\n",
    "1. Feature Extraction : Input -> HL1 -> HL2 -> Decoder -> Weight update\n",
    "2. Predict Features : Input -> HL1 -> HL2 -> Output\n",
    "3. Classification : Input of 3 -> HL1 -> HL2 -> Classifier -> Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras import optimizers, regularizers\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Contrast  Dissimilarity   Entropy  SumAverage  AutoCorrelation  \\\n",
      "0     0.060793       0.191241  0.508526    0.835470         0.747732   \n",
      "1     0.078852       0.185523  0.771363    0.424021         0.387763   \n",
      "2     0.166583       0.338598  0.671784    0.514270         0.369265   \n",
      "3     0.134599       0.289457  0.800151    0.421111         0.314318   \n",
      "4     0.163204       0.316215  0.858170    0.362923         0.275476   \n",
      "5     0.159482       0.294970  0.833486    0.319728         0.263842   \n",
      "6     0.142493       0.271786  0.835539    0.320574         0.268154   \n",
      "7     0.162361       0.315648  0.821376    0.364281         0.294706   \n",
      "8     0.079082       0.199192  0.815874    0.236465         0.160414   \n",
      "9     0.024976       0.094667  0.810382    0.103185         0.058975   \n",
      "10    0.218712       0.360935  0.656305    0.321504         0.271266   \n",
      "11    0.215487       0.407549  0.529382    0.592759         0.471366   \n",
      "12    0.131281       0.300418  0.667384    0.566679         0.452530   \n",
      "13    0.085469       0.223105  0.763238    0.455680         0.385185   \n",
      "14    0.100969       0.226698  0.769005    0.512903         0.451656   \n",
      "15    0.200468       0.396152  0.463638    0.694984         0.583093   \n",
      "16    0.100262       0.242284  0.685847    0.541492         0.449677   \n",
      "17    0.206314       0.396414  0.443256    0.711122         0.606940   \n",
      "18    0.059145       0.154835  0.762214    0.774734         0.695073   \n",
      "19    0.072964       0.132203  0.814470    0.782176         0.736818   \n",
      "20    0.061664       0.126099  0.842145    0.794030         0.732271   \n",
      "21    0.077908       0.176816  0.829278    0.627206         0.568222   \n",
      "22    0.060870       0.169655  0.728071    0.725733         0.627280   \n",
      "23    0.051295       0.172444  0.518110    0.862707         0.796527   \n",
      "24    0.106934       0.241507  0.677044    0.729305         0.642892   \n",
      "25    0.070374       0.207230  0.630192    0.742794         0.645432   \n",
      "26    0.048139       0.153067  0.775058    0.620342         0.517077   \n",
      "27    0.022700       0.090867  0.797040    0.179122         0.083151   \n",
      "28    0.140301       0.307815  0.435768    0.679693         0.545653   \n",
      "29    0.117832       0.255125  0.540630    0.797700         0.715573   \n",
      "...        ...            ...       ...         ...              ...   \n",
      "1864  0.558019       0.738067  0.328852    0.701583         0.559934   \n",
      "1865  0.632253       0.796315  0.279471    0.692461         0.546799   \n",
      "1866  0.320167       0.560097  0.224640    0.830943         0.722543   \n",
      "1867  0.558019       0.738067  0.328852    0.701583         0.559934   \n",
      "1868  0.413155       0.615203  0.224640    0.817389         0.703244   \n",
      "1869  0.298029       0.502339  0.141789    0.830299         0.728137   \n",
      "1870  0.309187       0.553827  0.264617    0.832961         0.725259   \n",
      "1871  0.610209       0.787585  0.411064    0.585411         0.440942   \n",
      "1872  0.508455       0.706965  0.315000    0.734983         0.600835   \n",
      "1873  0.452527       0.667712  0.346604    0.726140         0.593117   \n",
      "1874  0.287039       0.514776  0.465126    0.619096         0.497693   \n",
      "1875  0.156627       0.336048  0.444624    0.807244         0.700805   \n",
      "1876  0.194575       0.331983  0.647693    0.725029         0.629589   \n",
      "1877  0.221151       0.430924  0.407661    0.779383         0.675230   \n",
      "1878  0.179501       0.279494  0.655683    0.734811         0.654624   \n",
      "1879  0.158182       0.286349  0.619850    0.724741         0.647575   \n",
      "1880  0.506276       0.668610  0.466219    0.478653         0.359584   \n",
      "1881  0.818841       0.833995  0.410033    0.598224         0.450145   \n",
      "1882  0.423464       0.638060  0.442920    0.508853         0.397298   \n",
      "1883  0.449417       0.658689  0.419703    0.594301         0.469426   \n",
      "1884  0.364009       0.595114  0.322186    0.702402         0.567476   \n",
      "1885  0.108537       0.268683  0.417732    0.831226         0.741880   \n",
      "1886  0.159741       0.324771  0.605787    0.628002         0.539149   \n",
      "1887  0.139633       0.293974  0.590361    0.708155         0.609556   \n",
      "1888  0.108694       0.269008  0.443256    0.818751         0.732373   \n",
      "1889  0.306935       0.404837  0.446267    0.794822         0.713238   \n",
      "1890  0.346677       0.527088  0.545751    0.513068         0.411747   \n",
      "1891  0.399146       0.536537  0.603625    0.520881         0.431136   \n",
      "1892  0.312944       0.479218  0.444624    0.680166         0.580513   \n",
      "1893  0.444710       0.678709  0.283577    0.683001         0.553483   \n",
      "\n",
      "      Skewness  Kurtosis  MeanValue  Label  \n",
      "0     0.268454  0.129176   0.809935      1  \n",
      "1     0.161510  0.057792   0.401535      1  \n",
      "2     0.050808  0.010014   0.492886      1  \n",
      "3     0.079445  0.045560   0.411479      1  \n",
      "4     0.181040  0.114735   0.352080      1  \n",
      "5     0.200623  0.086659   0.314821      1  \n",
      "6     0.164073  0.070733   0.310854      1  \n",
      "7     0.141555  0.064682   0.348936      1  \n",
      "8     0.108641  0.039298   0.225617      1  \n",
      "9     0.212032  0.117523   0.092850      1  \n",
      "10    0.307882  0.167638   0.301859      1  \n",
      "11    0.334066  0.222054   0.544037      1  \n",
      "12    0.344002  0.245590   0.545506      1  \n",
      "13    0.153778  0.079277   0.430955      1  \n",
      "14    0.176705  0.064791   0.490926      1  \n",
      "15    0.363580  0.231104   0.676617      1  \n",
      "16    0.299532  0.185505   0.505491      1  \n",
      "17    0.322188  0.189297   0.665259      1  \n",
      "18    0.106261  0.022343   0.758524      1  \n",
      "19    0.136966  0.030201   0.761228      1  \n",
      "20    0.138680  0.033756   0.773271      1  \n",
      "21    0.188514  0.059769   0.599285      1  \n",
      "22    0.166483  0.075643   0.696191      1  \n",
      "23    0.661178  0.568231   0.841329      1  \n",
      "24    0.185415  0.069068   0.684824      1  \n",
      "25    0.339835  0.224346   0.711489      1  \n",
      "26    0.115889  0.045678   0.597149      1  \n",
      "27    0.031770  0.005009   0.174761      1  \n",
      "28    0.168123  0.053369   0.646215      1  \n",
      "29    0.328588  0.177856   0.761273      1  \n",
      "...        ...       ...        ...    ...  \n",
      "1864  0.627655  0.505224   0.629860      0  \n",
      "1865  0.395604  0.208320   0.622857      0  \n",
      "1866  0.374045  0.167740   0.787020      0  \n",
      "1867  0.627655  0.505224   0.629860      0  \n",
      "1868  0.492547  0.294777   0.774250      0  \n",
      "1869  0.346725  0.128502   0.781665      0  \n",
      "1870  0.575739  0.429014   0.788915      0  \n",
      "1871  0.295764  0.145571   0.504832      0  \n",
      "1872  0.602409  0.475090   0.663517      0  \n",
      "1873  0.530573  0.396947   0.665700      0  \n",
      "1874  0.368438  0.232848   0.552249      0  \n",
      "1875  0.410834  0.275418   0.807559      0  \n",
      "1876  0.158791  0.055215   0.675698      0  \n",
      "1877  0.561328  0.434162   0.734490      0  \n",
      "1878  0.194957  0.084162   0.693122      0  \n",
      "1879  0.192141  0.069799   0.681935      0  \n",
      "1880  0.379937  0.254102   0.412040      0  \n",
      "1881  0.454912  0.308965   0.552007      0  \n",
      "1882  0.310646  0.170752   0.446923      0  \n",
      "1883  0.265178  0.118484   0.524606      0  \n",
      "1884  0.321496  0.159043   0.635092      0  \n",
      "1885  0.352181  0.201639   0.790453      0  \n",
      "1886  0.325142  0.206001   0.587882      0  \n",
      "1887  0.226980  0.119472   0.672100      0  \n",
      "1888  0.314477  0.156936   0.776604      0  \n",
      "1889  0.319001  0.171715   0.730112      0  \n",
      "1890  0.359828  0.223460   0.451675      0  \n",
      "1891  0.426208  0.261866   0.461701      0  \n",
      "1892  0.310646  0.170752   0.613353      0  \n",
      "1893  0.316607  0.123765   0.630581      0  \n",
      "\n",
      "[1894 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# Preparing dataset - total 1596 images : 649 nodules + 947 non-nodules\n",
    "df = pd.read_csv('./Datas/nodules_labeled_normed.csv', index_col=0)\n",
    "# select seed to randomize - [0, 3136, 8405, 4242, 5293]\n",
    "np.random.seed(3136)\n",
    "\n",
    "# Resampling technique for solving Class Imbalance\n",
    "# Random over-sampling : nodules 649 -> 947\n",
    "nodule_os_idx = np.random.choice(649, 947-649)\n",
    "df_nodule_os = df.loc[nodule_os_idx]\n",
    "\n",
    "df_os = pd.concat([df, df_nodule_os])\n",
    "df_os.sort_values([\"Label\"], ascending=[False], inplace=True)\n",
    "df_os.reset_index(drop=True, inplace=True)\n",
    "df_os.drop([\"Energy\",\"Homogeneity\"], axis=1, inplace=True)\n",
    "print(df_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide training and test datasets - test datasets : 15 nodules, 15 non-nodules\n",
    "nodule_rand_idx = np.random.choice(947, 15)\n",
    "nonnodule_rand_idx = np.random.choice(947, 15)\n",
    "\n",
    "nodule_test = df_os.loc[nodule_rand_idx]\n",
    "nonnodule_test = df_os.loc[nonnodule_rand_idx + 946]\n",
    "\n",
    "# Delete the test datasets from dataframe\n",
    "df_t1 = df_os.drop(nodule_rand_idx, axis=0)\n",
    "df_train = df_t1.drop(nonnodule_rand_idx + 946, axis=0)\n",
    "df_test = pd.concat([nodule_test, nonnodule_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice the inputs and labels\n",
    "# iloc : use integer index for slice\n",
    "# loc : use label for slice\n",
    "cols = df_os.shape[1] - 1\n",
    "x_train = df_train.iloc[:, :cols] \n",
    "y_train_classifier = df_train.iloc[:, cols]\n",
    "y_labels_train = to_categorical(y_train_classifier)\n",
    "\n",
    "x_test_classifier = df_test.iloc[:, :cols]\n",
    "y_test_classifier = df_test.iloc[:, cols]\n",
    "y_labels_test = to_categorical(y_test_classifier)\n",
    "\n",
    "# add noise to the input data\n",
    "noise_factor = 0.1\n",
    "x_train_noisy = x_train * (1 + noise_factor *\\\n",
    "            np.random.binomial(n=1, p=0.1, size=x_train.shape) )\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build Autoencoder\n",
    "# Input placeholder\n",
    "input_data = Input(shape=(cols,))\n",
    "\n",
    "# Hidden Layer 1\n",
    "hidden_1 = Dense(6, activation='relu', kernel_initializer='he_normal',\n",
    "                    )(input_data)\n",
    "\n",
    "# Hidden Layer 2\n",
    "hidden_2 = Dense(4, activation='relu', kernel_initializer='he_normal',\n",
    "                    )(hidden_1)\n",
    "\n",
    "# Decoded Layer 1\n",
    "decoded_1 = Dense(6, activation='relu', kernel_initializer='he_normal')(hidden_2)\n",
    "\n",
    "# Decoded Layer 2 (reconstructed data)\n",
    "decoded_2 = Dense(cols, activation='sigmoid', kernel_initializer='he_normal')(decoded_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 4)                 28        \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 6)                 30        \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 8)                 56        \n",
      "=================================================================\n",
      "Total params: 168\n",
      "Trainable params: 168\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# this model maps an input to its reconstruction\n",
    "autoencoder_recon = Model(input_data, decoded_2)\n",
    "autoencoder_recon.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "autoencoder_recon.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1770 samples, validate on 94 samples\n",
      "Epoch 1/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5571 - val_loss: 0.6060\n",
      "Epoch 2/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5571 - val_loss: 0.6060\n",
      "Epoch 3/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5571 - val_loss: 0.6060\n",
      "Epoch 4/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5571 - val_loss: 0.6060\n",
      "Epoch 5/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5571 - val_loss: 0.6061\n",
      "Epoch 6/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5571 - val_loss: 0.6060\n",
      "Epoch 7/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5570 - val_loss: 0.6059\n",
      "Epoch 8/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5570 - val_loss: 0.6060\n",
      "Epoch 9/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5570 - val_loss: 0.6060\n",
      "Epoch 10/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5571 - val_loss: 0.6061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5571 - val_loss: 0.6059\n",
      "Epoch 12/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5570 - val_loss: 0.6060\n",
      "Epoch 13/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5570 - val_loss: 0.6059\n",
      "Epoch 14/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5570 - val_loss: 0.6060\n",
      "Epoch 15/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5570 - val_loss: 0.6060\n",
      "Epoch 16/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5570 - val_loss: 0.6060\n",
      "Epoch 17/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5571 - val_loss: 0.6060\n",
      "Epoch 18/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5570 - val_loss: 0.6059\n",
      "Epoch 19/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5570 - val_loss: 0.6060\n",
      "Epoch 20/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5571 - val_loss: 0.6060\n",
      "Epoch 21/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5570 - val_loss: 0.6061\n",
      "Epoch 22/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5570 - val_loss: 0.6060\n",
      "Epoch 23/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5570 - val_loss: 0.6060\n",
      "Epoch 24/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5570 - val_loss: 0.6061\n",
      "Epoch 25/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5570 - val_loss: 0.6060\n",
      "Epoch 26/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5569 - val_loss: 0.6059\n",
      "Epoch 27/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5569 - val_loss: 0.6058\n",
      "Epoch 28/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5569 - val_loss: 0.6059\n",
      "Epoch 29/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5569 - val_loss: 0.6059\n",
      "Epoch 30/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5569 - val_loss: 0.6059\n",
      "Epoch 31/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5569 - val_loss: 0.6058\n",
      "Epoch 32/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5568 - val_loss: 0.6059\n",
      "Epoch 33/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5568 - val_loss: 0.6058\n",
      "Epoch 34/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5569 - val_loss: 0.6059\n",
      "Epoch 35/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5569 - val_loss: 0.6059\n",
      "Epoch 36/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5569 - val_loss: 0.6058\n",
      "Epoch 37/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5568 - val_loss: 0.6059\n",
      "Epoch 38/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5568 - val_loss: 0.6058\n",
      "Epoch 39/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5568 - val_loss: 0.6058\n",
      "Epoch 40/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5568 - val_loss: 0.6059\n",
      "Epoch 41/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5568 - val_loss: 0.6059\n",
      "Epoch 42/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5569 - val_loss: 0.6060\n",
      "Epoch 43/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5569 - val_loss: 0.6058\n",
      "Epoch 44/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5569 - val_loss: 0.6062\n",
      "Epoch 45/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5570 - val_loss: 0.6059\n",
      "Epoch 46/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5568 - val_loss: 0.6058\n",
      "Epoch 47/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5568 - val_loss: 0.6058\n",
      "Epoch 48/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5568 - val_loss: 0.6059\n",
      "Epoch 49/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5569 - val_loss: 0.6059\n",
      "Epoch 50/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5569 - val_loss: 0.6060\n",
      "Epoch 51/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5568 - val_loss: 0.6058\n",
      "Epoch 52/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5567 - val_loss: 0.6059\n",
      "Epoch 53/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5568 - val_loss: 0.6059\n",
      "Epoch 54/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5567 - val_loss: 0.6058\n",
      "Epoch 55/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5567 - val_loss: 0.6058\n",
      "Epoch 56/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5567 - val_loss: 0.6059\n",
      "Epoch 57/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5568 - val_loss: 0.6060\n",
      "Epoch 58/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5569 - val_loss: 0.6060\n",
      "Epoch 59/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5568 - val_loss: 0.6057\n",
      "Epoch 60/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5566 - val_loss: 0.6057\n",
      "Epoch 61/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5567 - val_loss: 0.6059\n",
      "Epoch 62/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5567 - val_loss: 0.6057\n",
      "Epoch 63/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5566 - val_loss: 0.6057\n",
      "Epoch 64/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5566 - val_loss: 0.6057\n",
      "Epoch 65/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5566 - val_loss: 0.6058\n",
      "Epoch 66/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5566 - val_loss: 0.6057\n",
      "Epoch 67/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5567 - val_loss: 0.6058\n",
      "Epoch 68/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5567 - val_loss: 0.6059\n",
      "Epoch 69/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5567 - val_loss: 0.6058\n",
      "Epoch 70/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5566 - val_loss: 0.6058\n",
      "Epoch 71/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5566 - val_loss: 0.6058\n",
      "Epoch 72/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5566 - val_loss: 0.6058\n",
      "Epoch 73/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5566 - val_loss: 0.6058\n",
      "Epoch 74/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5567 - val_loss: 0.6059\n",
      "Epoch 75/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5567 - val_loss: 0.6058\n",
      "Epoch 76/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5567 - val_loss: 0.6058\n",
      "Epoch 77/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5566 - val_loss: 0.6057\n",
      "Epoch 78/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5565 - val_loss: 0.6057\n",
      "Epoch 79/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5566 - val_loss: 0.6058\n",
      "Epoch 80/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5565 - val_loss: 0.6057\n",
      "Epoch 81/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5566 - val_loss: 0.6058\n",
      "Epoch 82/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5565 - val_loss: 0.6057\n",
      "Epoch 83/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5565 - val_loss: 0.6057\n",
      "Epoch 84/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5566 - val_loss: 0.6057\n",
      "Epoch 85/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5566 - val_loss: 0.6058\n",
      "Epoch 86/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5566 - val_loss: 0.6057\n",
      "Epoch 87/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5566 - val_loss: 0.6059\n",
      "Epoch 88/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5566 - val_loss: 0.6056\n",
      "Epoch 89/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5565 - val_loss: 0.6056\n",
      "Epoch 90/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5565 - val_loss: 0.6056\n",
      "Epoch 91/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5565 - val_loss: 0.6056\n",
      "Epoch 92/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5565 - val_loss: 0.6056\n",
      "Epoch 93/1000\n",
      "1770/1770 [==============================] - 0s 12us/step - loss: 0.5564 - val_loss: 0.6055\n",
      "Epoch 94/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5564 - val_loss: 0.6055\n",
      "Epoch 95/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5564 - val_loss: 0.6056\n",
      "Epoch 96/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5565 - val_loss: 0.6056\n",
      "Epoch 97/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5565 - val_loss: 0.6058\n",
      "Epoch 98/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5565 - val_loss: 0.6056\n",
      "Epoch 99/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5564 - val_loss: 0.6057\n",
      "Epoch 100/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5564 - val_loss: 0.6056\n",
      "Epoch 101/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5564 - val_loss: 0.6057\n",
      "Epoch 102/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5565 - val_loss: 0.6056\n",
      "Epoch 103/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5565 - val_loss: 0.6056\n",
      "Epoch 104/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5565 - val_loss: 0.6056\n",
      "Epoch 105/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5565 - val_loss: 0.6057\n",
      "Epoch 106/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5565 - val_loss: 0.6055\n",
      "Epoch 107/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5564 - val_loss: 0.6055\n",
      "Epoch 108/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5564 - val_loss: 0.6055\n",
      "Epoch 109/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5563 - val_loss: 0.6055\n",
      "Epoch 110/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5564 - val_loss: 0.6055\n",
      "Epoch 111/1000\n",
      "1770/1770 [==============================] - 0s 12us/step - loss: 0.5564 - val_loss: 0.6055\n",
      "Epoch 112/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5564 - val_loss: 0.6056\n",
      "Epoch 113/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5564 - val_loss: 0.6057\n",
      "Epoch 114/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5564 - val_loss: 0.6055\n",
      "Epoch 115/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5564 - val_loss: 0.6056\n",
      "Epoch 116/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5565 - val_loss: 0.6056\n",
      "Epoch 117/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5563 - val_loss: 0.6054\n",
      "Epoch 118/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5563 - val_loss: 0.6055\n",
      "Epoch 119/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5564 - val_loss: 0.6056\n",
      "Epoch 120/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5564 - val_loss: 0.6055\n",
      "Epoch 121/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5564 - val_loss: 0.6056\n",
      "Epoch 122/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5563 - val_loss: 0.6055\n",
      "Epoch 123/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5563 - val_loss: 0.6056\n",
      "Epoch 124/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5563 - val_loss: 0.6055\n",
      "Epoch 125/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5563 - val_loss: 0.6056\n",
      "Epoch 126/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5563 - val_loss: 0.6054\n",
      "Epoch 127/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5564 - val_loss: 0.6055\n",
      "Epoch 128/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5563 - val_loss: 0.6055\n",
      "Epoch 129/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5563 - val_loss: 0.6056\n",
      "Epoch 130/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5564 - val_loss: 0.6055\n",
      "Epoch 131/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5563 - val_loss: 0.6054\n",
      "Epoch 132/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5563 - val_loss: 0.6055\n",
      "Epoch 133/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5564 - val_loss: 0.6057\n",
      "Epoch 134/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5564 - val_loss: 0.6054\n",
      "Epoch 135/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5563 - val_loss: 0.6056\n",
      "Epoch 136/1000\n",
      "1770/1770 [==============================] - 0s 12us/step - loss: 0.5563 - val_loss: 0.6055\n",
      "Epoch 137/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5563 - val_loss: 0.6054\n",
      "Epoch 138/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5563 - val_loss: 0.6054\n",
      "Epoch 139/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5562 - val_loss: 0.6054\n",
      "Epoch 140/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5562 - val_loss: 0.6053\n",
      "Epoch 141/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5563 - val_loss: 0.6056\n",
      "Epoch 142/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5563 - val_loss: 0.6055\n",
      "Epoch 143/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5564 - val_loss: 0.6057\n",
      "Epoch 144/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5562 - val_loss: 0.6054\n",
      "Epoch 145/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5562 - val_loss: 0.6055\n",
      "Epoch 146/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5562 - val_loss: 0.6052\n",
      "Epoch 147/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5562 - val_loss: 0.6055\n",
      "Epoch 148/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5562 - val_loss: 0.6053\n",
      "Epoch 149/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5561 - val_loss: 0.6053\n",
      "Epoch 150/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5561 - val_loss: 0.6054\n",
      "Epoch 151/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5561 - val_loss: 0.6052\n",
      "Epoch 152/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5561 - val_loss: 0.6052\n",
      "Epoch 153/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5561 - val_loss: 0.6053\n",
      "Epoch 154/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5562 - val_loss: 0.6054\n",
      "Epoch 155/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5563 - val_loss: 0.6055\n",
      "Epoch 156/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5562 - val_loss: 0.6054\n",
      "Epoch 157/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5562 - val_loss: 0.6054\n",
      "Epoch 158/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5562 - val_loss: 0.6054\n",
      "Epoch 159/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5562 - val_loss: 0.6056\n",
      "Epoch 160/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5562 - val_loss: 0.6053\n",
      "Epoch 161/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5561 - val_loss: 0.6053\n",
      "Epoch 162/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5560 - val_loss: 0.6052\n",
      "Epoch 163/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5561 - val_loss: 0.6054\n",
      "Epoch 164/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5561 - val_loss: 0.6053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5561 - val_loss: 0.6053\n",
      "Epoch 166/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5560 - val_loss: 0.6052\n",
      "Epoch 167/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5560 - val_loss: 0.6053\n",
      "Epoch 168/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5560 - val_loss: 0.6051\n",
      "Epoch 169/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5560 - val_loss: 0.6052\n",
      "Epoch 170/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5560 - val_loss: 0.6053\n",
      "Epoch 171/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5560 - val_loss: 0.6053\n",
      "Epoch 172/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5560 - val_loss: 0.6052\n",
      "Epoch 173/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5560 - val_loss: 0.6053\n",
      "Epoch 174/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5560 - val_loss: 0.6052\n",
      "Epoch 175/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5560 - val_loss: 0.6052\n",
      "Epoch 176/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5560 - val_loss: 0.6052\n",
      "Epoch 177/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5560 - val_loss: 0.6052\n",
      "Epoch 178/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5559 - val_loss: 0.6052\n",
      "Epoch 179/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5559 - val_loss: 0.6052\n",
      "Epoch 180/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5560 - val_loss: 0.6052\n",
      "Epoch 181/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5560 - val_loss: 0.6053\n",
      "Epoch 182/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5561 - val_loss: 0.6053\n",
      "Epoch 183/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5561 - val_loss: 0.6053\n",
      "Epoch 184/1000\n",
      "1770/1770 [==============================] - 0s 12us/step - loss: 0.5561 - val_loss: 0.6054\n",
      "Epoch 185/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5560 - val_loss: 0.6053\n",
      "Epoch 186/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5560 - val_loss: 0.6053\n",
      "Epoch 187/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5562 - val_loss: 0.6056\n",
      "Epoch 188/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5562 - val_loss: 0.6053\n",
      "Epoch 189/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5560 - val_loss: 0.6052\n",
      "Epoch 190/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5559 - val_loss: 0.6051\n",
      "Epoch 191/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5559 - val_loss: 0.6051\n",
      "Epoch 192/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5560 - val_loss: 0.6051\n",
      "Epoch 193/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5559 - val_loss: 0.6051\n",
      "Epoch 194/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5559 - val_loss: 0.6051\n",
      "Epoch 195/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5559 - val_loss: 0.6051\n",
      "Epoch 196/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5559 - val_loss: 0.6051\n",
      "Epoch 197/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5558 - val_loss: 0.6051\n",
      "Epoch 198/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5559 - val_loss: 0.6051\n",
      "Epoch 199/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5558 - val_loss: 0.6052\n",
      "Epoch 200/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5559 - val_loss: 0.6052\n",
      "Epoch 201/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5559 - val_loss: 0.6052\n",
      "Epoch 202/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5559 - val_loss: 0.6051\n",
      "Epoch 203/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5558 - val_loss: 0.6050\n",
      "Epoch 204/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5559 - val_loss: 0.6051\n",
      "Epoch 205/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5558 - val_loss: 0.6050\n",
      "Epoch 206/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5558 - val_loss: 0.6050\n",
      "Epoch 207/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5558 - val_loss: 0.6052\n",
      "Epoch 208/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5558 - val_loss: 0.6050\n",
      "Epoch 209/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5558 - val_loss: 0.6051\n",
      "Epoch 210/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5557 - val_loss: 0.6049\n",
      "Epoch 211/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5557 - val_loss: 0.6049\n",
      "Epoch 212/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5558 - val_loss: 0.6051\n",
      "Epoch 213/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5558 - val_loss: 0.6051\n",
      "Epoch 214/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5557 - val_loss: 0.6050\n",
      "Epoch 215/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5557 - val_loss: 0.6050\n",
      "Epoch 216/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5558 - val_loss: 0.6049\n",
      "Epoch 217/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5557 - val_loss: 0.6050\n",
      "Epoch 218/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5558 - val_loss: 0.6050\n",
      "Epoch 219/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5557 - val_loss: 0.6049\n",
      "Epoch 220/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5559 - val_loss: 0.6050\n",
      "Epoch 221/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5559 - val_loss: 0.6050\n",
      "Epoch 222/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5558 - val_loss: 0.6050\n",
      "Epoch 223/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5558 - val_loss: 0.6049\n",
      "Epoch 224/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5557 - val_loss: 0.6049\n",
      "Epoch 225/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5557 - val_loss: 0.6048\n",
      "Epoch 226/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5557 - val_loss: 0.6049\n",
      "Epoch 227/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5556 - val_loss: 0.6050\n",
      "Epoch 228/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5556 - val_loss: 0.6049\n",
      "Epoch 229/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5556 - val_loss: 0.6048\n",
      "Epoch 230/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5558 - val_loss: 0.6050\n",
      "Epoch 231/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5559 - val_loss: 0.6050\n",
      "Epoch 232/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5558 - val_loss: 0.6050\n",
      "Epoch 233/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5557 - val_loss: 0.6048\n",
      "Epoch 234/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5556 - val_loss: 0.6048\n",
      "Epoch 235/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5556 - val_loss: 0.6048\n",
      "Epoch 236/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5556 - val_loss: 0.6048\n",
      "Epoch 237/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5556 - val_loss: 0.6047\n",
      "Epoch 238/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5556 - val_loss: 0.6048\n",
      "Epoch 239/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5556 - val_loss: 0.6048\n",
      "Epoch 240/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5556 - val_loss: 0.6049\n",
      "Epoch 241/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5555 - val_loss: 0.6048\n",
      "Epoch 242/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5555 - val_loss: 0.6048\n",
      "Epoch 243/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5556 - val_loss: 0.6048\n",
      "Epoch 244/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5556 - val_loss: 0.6048\n",
      "Epoch 245/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5555 - val_loss: 0.6048\n",
      "Epoch 246/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5556 - val_loss: 0.6047\n",
      "Epoch 247/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5555 - val_loss: 0.6048\n",
      "Epoch 248/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5556 - val_loss: 0.6047\n",
      "Epoch 249/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5555 - val_loss: 0.6047\n",
      "Epoch 250/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5555 - val_loss: 0.6048\n",
      "Epoch 251/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5555 - val_loss: 0.6047\n",
      "Epoch 252/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5556 - val_loss: 0.6047\n",
      "Epoch 253/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5555 - val_loss: 0.6048\n",
      "Epoch 254/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5555 - val_loss: 0.6047\n",
      "Epoch 255/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5556 - val_loss: 0.6048\n",
      "Epoch 256/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5555 - val_loss: 0.6048\n",
      "Epoch 257/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5555 - val_loss: 0.6046\n",
      "Epoch 258/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5555 - val_loss: 0.6047\n",
      "Epoch 259/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5555 - val_loss: 0.6047\n",
      "Epoch 260/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5555 - val_loss: 0.6048\n",
      "Epoch 261/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5555 - val_loss: 0.6047\n",
      "Epoch 262/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5554 - val_loss: 0.6047\n",
      "Epoch 263/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5554 - val_loss: 0.6047\n",
      "Epoch 264/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5554 - val_loss: 0.6046\n",
      "Epoch 265/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5554 - val_loss: 0.6046\n",
      "Epoch 266/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5555 - val_loss: 0.6046\n",
      "Epoch 267/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5556 - val_loss: 0.6048\n",
      "Epoch 268/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5554 - val_loss: 0.6046\n",
      "Epoch 269/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5554 - val_loss: 0.6046\n",
      "Epoch 270/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5554 - val_loss: 0.6046\n",
      "Epoch 271/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5554 - val_loss: 0.6046\n",
      "Epoch 272/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5554 - val_loss: 0.6046\n",
      "Epoch 273/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5553 - val_loss: 0.6045\n",
      "Epoch 274/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5553 - val_loss: 0.6046\n",
      "Epoch 275/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5554 - val_loss: 0.6047\n",
      "Epoch 276/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5554 - val_loss: 0.6046\n",
      "Epoch 277/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5553 - val_loss: 0.6046\n",
      "Epoch 278/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5553 - val_loss: 0.6045\n",
      "Epoch 279/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5553 - val_loss: 0.6045\n",
      "Epoch 280/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5553 - val_loss: 0.6045\n",
      "Epoch 281/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5553 - val_loss: 0.6045\n",
      "Epoch 282/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5553 - val_loss: 0.6044\n",
      "Epoch 283/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5553 - val_loss: 0.6045\n",
      "Epoch 284/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5553 - val_loss: 0.6047\n",
      "Epoch 285/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5553 - val_loss: 0.6044\n",
      "Epoch 286/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5553 - val_loss: 0.6046\n",
      "Epoch 287/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5553 - val_loss: 0.6046\n",
      "Epoch 288/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5554 - val_loss: 0.6046\n",
      "Epoch 289/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5554 - val_loss: 0.6045\n",
      "Epoch 290/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5554 - val_loss: 0.6047\n",
      "Epoch 291/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5553 - val_loss: 0.6045\n",
      "Epoch 292/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5553 - val_loss: 0.6045\n",
      "Epoch 293/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5553 - val_loss: 0.6044\n",
      "Epoch 294/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5552 - val_loss: 0.6044\n",
      "Epoch 295/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5552 - val_loss: 0.6044\n",
      "Epoch 296/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5552 - val_loss: 0.6044\n",
      "Epoch 297/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5552 - val_loss: 0.6045\n",
      "Epoch 298/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5552 - val_loss: 0.6045\n",
      "Epoch 299/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5552 - val_loss: 0.6044\n",
      "Epoch 300/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5552 - val_loss: 0.6045\n",
      "Epoch 301/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5552 - val_loss: 0.6044\n",
      "Epoch 302/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5551 - val_loss: 0.6043\n",
      "Epoch 303/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5551 - val_loss: 0.6043\n",
      "Epoch 304/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5551 - val_loss: 0.6043\n",
      "Epoch 305/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5551 - val_loss: 0.6043\n",
      "Epoch 306/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5551 - val_loss: 0.6043\n",
      "Epoch 307/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5551 - val_loss: 0.6044\n",
      "Epoch 308/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5552 - val_loss: 0.6043\n",
      "Epoch 309/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5552 - val_loss: 0.6043\n",
      "Epoch 310/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5551 - val_loss: 0.6044\n",
      "Epoch 311/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5551 - val_loss: 0.6043\n",
      "Epoch 312/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5551 - val_loss: 0.6043\n",
      "Epoch 313/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5551 - val_loss: 0.6045\n",
      "Epoch 314/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5552 - val_loss: 0.6045\n",
      "Epoch 315/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5552 - val_loss: 0.6044\n",
      "Epoch 316/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5551 - val_loss: 0.6043\n",
      "Epoch 317/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5551 - val_loss: 0.6043\n",
      "Epoch 318/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5550 - val_loss: 0.6043\n",
      "Epoch 319/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5551 - val_loss: 0.6043\n",
      "Epoch 320/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5550 - val_loss: 0.6042\n",
      "Epoch 321/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5550 - val_loss: 0.6042\n",
      "Epoch 322/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5551 - val_loss: 0.6043\n",
      "Epoch 323/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5550 - val_loss: 0.6043\n",
      "Epoch 324/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5551 - val_loss: 0.6043\n",
      "Epoch 325/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5551 - val_loss: 0.6042\n",
      "Epoch 326/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5551 - val_loss: 0.6043\n",
      "Epoch 327/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5550 - val_loss: 0.6042\n",
      "Epoch 328/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5550 - val_loss: 0.6043\n",
      "Epoch 329/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5550 - val_loss: 0.6041\n",
      "Epoch 330/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5550 - val_loss: 0.6043\n",
      "Epoch 331/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5551 - val_loss: 0.6042\n",
      "Epoch 332/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5550 - val_loss: 0.6042\n",
      "Epoch 333/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5549 - val_loss: 0.6042\n",
      "Epoch 334/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5550 - val_loss: 0.6043\n",
      "Epoch 335/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5550 - val_loss: 0.6042\n",
      "Epoch 336/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5550 - val_loss: 0.6041\n",
      "Epoch 337/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5550 - val_loss: 0.6041\n",
      "Epoch 338/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5549 - val_loss: 0.6041\n",
      "Epoch 339/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5550 - val_loss: 0.6041\n",
      "Epoch 340/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5549 - val_loss: 0.6042\n",
      "Epoch 341/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5550 - val_loss: 0.6043\n",
      "Epoch 342/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5550 - val_loss: 0.6041\n",
      "Epoch 343/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5550 - val_loss: 0.6042\n",
      "Epoch 344/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5549 - val_loss: 0.6041\n",
      "Epoch 345/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5549 - val_loss: 0.6041\n",
      "Epoch 346/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5549 - val_loss: 0.6042\n",
      "Epoch 347/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5549 - val_loss: 0.6041\n",
      "Epoch 348/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5550 - val_loss: 0.6043\n",
      "Epoch 349/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5550 - val_loss: 0.6040\n",
      "Epoch 350/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5549 - val_loss: 0.6041\n",
      "Epoch 351/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5549 - val_loss: 0.6040\n",
      "Epoch 352/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5548 - val_loss: 0.6040\n",
      "Epoch 353/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5548 - val_loss: 0.6041\n",
      "Epoch 354/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5548 - val_loss: 0.6041\n",
      "Epoch 355/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5549 - val_loss: 0.6039\n",
      "Epoch 356/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5548 - val_loss: 0.6039\n",
      "Epoch 357/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5548 - val_loss: 0.6041\n",
      "Epoch 358/1000\n",
      "1770/1770 [==============================] - 0s 12us/step - loss: 0.5548 - val_loss: 0.6040\n",
      "Epoch 359/1000\n",
      "1770/1770 [==============================] - 0s 12us/step - loss: 0.5548 - val_loss: 0.6039\n",
      "Epoch 360/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5548 - val_loss: 0.6040\n",
      "Epoch 361/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5549 - val_loss: 0.6042\n",
      "Epoch 362/1000\n",
      "1770/1770 [==============================] - 0s 12us/step - loss: 0.5549 - val_loss: 0.6040\n",
      "Epoch 363/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5549 - val_loss: 0.6041\n",
      "Epoch 364/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5549 - val_loss: 0.6041\n",
      "Epoch 365/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5548 - val_loss: 0.6039\n",
      "Epoch 366/1000\n",
      "1770/1770 [==============================] - 0s 12us/step - loss: 0.5547 - val_loss: 0.6039\n",
      "Epoch 367/1000\n",
      "1770/1770 [==============================] - 0s 12us/step - loss: 0.5548 - val_loss: 0.6040\n",
      "Epoch 368/1000\n",
      "1770/1770 [==============================] - 0s 12us/step - loss: 0.5549 - val_loss: 0.6042\n",
      "Epoch 369/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5548 - val_loss: 0.6039\n",
      "Epoch 370/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5548 - val_loss: 0.6039\n",
      "Epoch 371/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5548 - val_loss: 0.6041\n",
      "Epoch 372/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5548 - val_loss: 0.6039\n",
      "Epoch 373/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5548 - val_loss: 0.6040\n",
      "Epoch 374/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5547 - val_loss: 0.6039\n",
      "Epoch 375/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5547 - val_loss: 0.6038\n",
      "Epoch 376/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5547 - val_loss: 0.6038\n",
      "Epoch 377/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5547 - val_loss: 0.6039\n",
      "Epoch 378/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5547 - val_loss: 0.6039\n",
      "Epoch 379/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5548 - val_loss: 0.6039\n",
      "Epoch 380/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5547 - val_loss: 0.6039\n",
      "Epoch 381/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5547 - val_loss: 0.6038\n",
      "Epoch 382/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5547 - val_loss: 0.6039\n",
      "Epoch 383/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5546 - val_loss: 0.6038\n",
      "Epoch 384/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5546 - val_loss: 0.6039\n",
      "Epoch 385/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5547 - val_loss: 0.6037\n",
      "Epoch 386/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5546 - val_loss: 0.6038\n",
      "Epoch 387/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5547 - val_loss: 0.6039\n",
      "Epoch 388/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5548 - val_loss: 0.6040\n",
      "Epoch 389/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5548 - val_loss: 0.6040\n",
      "Epoch 390/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5548 - val_loss: 0.6038\n",
      "Epoch 391/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5546 - val_loss: 0.6038\n",
      "Epoch 392/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5546 - val_loss: 0.6037\n",
      "Epoch 393/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5546 - val_loss: 0.6038\n",
      "Epoch 394/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5546 - val_loss: 0.6037\n",
      "Epoch 395/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5546 - val_loss: 0.6038\n",
      "Epoch 396/1000\n",
      "1770/1770 [==============================] - 0s 12us/step - loss: 0.5546 - val_loss: 0.6037\n",
      "Epoch 397/1000\n",
      "1770/1770 [==============================] - 0s 12us/step - loss: 0.5546 - val_loss: 0.6037\n",
      "Epoch 398/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5546 - val_loss: 0.6038\n",
      "Epoch 399/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5546 - val_loss: 0.6038\n",
      "Epoch 400/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5546 - val_loss: 0.6037\n",
      "Epoch 401/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5546 - val_loss: 0.6037\n",
      "Epoch 402/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5546 - val_loss: 0.6037\n",
      "Epoch 403/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5546 - val_loss: 0.6037\n",
      "Epoch 404/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5546 - val_loss: 0.6038\n",
      "Epoch 405/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5546 - val_loss: 0.6038\n",
      "Epoch 406/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5546 - val_loss: 0.6038\n",
      "Epoch 407/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5546 - val_loss: 0.6037\n",
      "Epoch 408/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5546 - val_loss: 0.6037\n",
      "Epoch 409/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5546 - val_loss: 0.6036\n",
      "Epoch 410/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5545 - val_loss: 0.6037\n",
      "Epoch 411/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5545 - val_loss: 0.6037\n",
      "Epoch 412/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5545 - val_loss: 0.6038\n",
      "Epoch 413/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5546 - val_loss: 0.6037\n",
      "Epoch 414/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5545 - val_loss: 0.6037\n",
      "Epoch 415/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5545 - val_loss: 0.6038\n",
      "Epoch 416/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5545 - val_loss: 0.6037\n",
      "Epoch 417/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5546 - val_loss: 0.6036\n",
      "Epoch 418/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5545 - val_loss: 0.6037\n",
      "Epoch 419/1000\n",
      "1770/1770 [==============================] - 0s 12us/step - loss: 0.5547 - val_loss: 0.6037\n",
      "Epoch 420/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5545 - val_loss: 0.6037\n",
      "Epoch 421/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5545 - val_loss: 0.6036\n",
      "Epoch 422/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5545 - val_loss: 0.6036\n",
      "Epoch 423/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5545 - val_loss: 0.6036\n",
      "Epoch 424/1000\n",
      "1770/1770 [==============================] - 0s 9us/step - loss: 0.5545 - val_loss: 0.6037\n",
      "Epoch 425/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5545 - val_loss: 0.6037\n",
      "Epoch 426/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5546 - val_loss: 0.6037\n",
      "Epoch 427/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5545 - val_loss: 0.6036\n",
      "Epoch 428/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5545 - val_loss: 0.6037\n",
      "Epoch 429/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5545 - val_loss: 0.6036\n",
      "Epoch 430/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5545 - val_loss: 0.6036\n",
      "Epoch 431/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5544 - val_loss: 0.6037\n",
      "Epoch 432/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5545 - val_loss: 0.6036\n",
      "Epoch 433/1000\n",
      "1770/1770 [==============================] - 0s 12us/step - loss: 0.5545 - val_loss: 0.6036\n",
      "Epoch 434/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5544 - val_loss: 0.6036\n",
      "Epoch 435/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5545 - val_loss: 0.6036\n",
      "Epoch 436/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5544 - val_loss: 0.6035\n",
      "Epoch 437/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5544 - val_loss: 0.6035\n",
      "Epoch 438/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5544 - val_loss: 0.6036\n",
      "Epoch 439/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5544 - val_loss: 0.6036\n",
      "Epoch 440/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5545 - val_loss: 0.6036\n",
      "Epoch 441/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5545 - val_loss: 0.6036\n",
      "Epoch 442/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5545 - val_loss: 0.6035\n",
      "Epoch 443/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5544 - val_loss: 0.6036\n",
      "Epoch 444/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5545 - val_loss: 0.6037\n",
      "Epoch 445/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5546 - val_loss: 0.6037\n",
      "Epoch 446/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5545 - val_loss: 0.6035\n",
      "Epoch 447/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5544 - val_loss: 0.6035\n",
      "Epoch 448/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5544 - val_loss: 0.6035\n",
      "Epoch 449/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5544 - val_loss: 0.6036\n",
      "Epoch 450/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5545 - val_loss: 0.6036\n",
      "Epoch 451/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5546 - val_loss: 0.6036\n",
      "Epoch 452/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5544 - val_loss: 0.6036\n",
      "Epoch 453/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5544 - val_loss: 0.6035\n",
      "Epoch 454/1000\n",
      "1770/1770 [==============================] - 0s 12us/step - loss: 0.5544 - val_loss: 0.6035\n",
      "Epoch 455/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5544 - val_loss: 0.6035\n",
      "Epoch 456/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5545 - val_loss: 0.6036\n",
      "Epoch 457/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5545 - val_loss: 0.6036\n",
      "Epoch 458/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5544 - val_loss: 0.6034\n",
      "Epoch 459/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5544 - val_loss: 0.6035\n",
      "Epoch 460/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5544 - val_loss: 0.6036\n",
      "Epoch 461/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5544 - val_loss: 0.6034\n",
      "Epoch 462/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5544 - val_loss: 0.6036\n",
      "Epoch 463/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5544 - val_loss: 0.6034\n",
      "Epoch 464/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5543 - val_loss: 0.6035\n",
      "Epoch 465/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5543 - val_loss: 0.6035\n",
      "Epoch 466/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5543 - val_loss: 0.6034\n",
      "Epoch 467/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5544 - val_loss: 0.6035\n",
      "Epoch 468/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5544 - val_loss: 0.6035\n",
      "Epoch 469/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5544 - val_loss: 0.6036\n",
      "Epoch 470/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5545 - val_loss: 0.6034\n",
      "Epoch 471/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5544 - val_loss: 0.6034\n",
      "Epoch 472/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5543 - val_loss: 0.6035\n",
      "Epoch 473/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5543 - val_loss: 0.6034\n",
      "Epoch 474/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5543 - val_loss: 0.6034\n",
      "Epoch 475/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5543 - val_loss: 0.6034\n",
      "Epoch 476/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5543 - val_loss: 0.6034\n",
      "Epoch 477/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5543 - val_loss: 0.6034\n",
      "Epoch 478/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5543 - val_loss: 0.6034\n",
      "Epoch 479/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5543 - val_loss: 0.6035\n",
      "Epoch 480/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5543 - val_loss: 0.6034\n",
      "Epoch 481/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5543 - val_loss: 0.6035\n",
      "Epoch 482/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5544 - val_loss: 0.6034\n",
      "Epoch 483/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5545 - val_loss: 0.6034\n",
      "Epoch 484/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5543 - val_loss: 0.6034\n",
      "Epoch 485/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5543 - val_loss: 0.6033\n",
      "Epoch 486/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5543 - val_loss: 0.6033\n",
      "Epoch 487/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5543 - val_loss: 0.6033\n",
      "Epoch 488/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5542 - val_loss: 0.6034\n",
      "Epoch 489/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5543 - val_loss: 0.6034\n",
      "Epoch 490/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5543 - val_loss: 0.6034\n",
      "Epoch 491/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5543 - val_loss: 0.6034\n",
      "Epoch 492/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5543 - val_loss: 0.6034\n",
      "Epoch 493/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5543 - val_loss: 0.6033\n",
      "Epoch 494/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5542 - val_loss: 0.6033\n",
      "Epoch 495/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5543 - val_loss: 0.6034\n",
      "Epoch 496/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5543 - val_loss: 0.6033\n",
      "Epoch 497/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5543 - val_loss: 0.6034\n",
      "Epoch 498/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5542 - val_loss: 0.6033\n",
      "Epoch 499/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5542 - val_loss: 0.6033\n",
      "Epoch 500/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5542 - val_loss: 0.6034\n",
      "Epoch 501/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5543 - val_loss: 0.6034\n",
      "Epoch 502/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5542 - val_loss: 0.6033\n",
      "Epoch 503/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5543 - val_loss: 0.6033\n",
      "Epoch 504/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5542 - val_loss: 0.6033\n",
      "Epoch 505/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5542 - val_loss: 0.6033\n",
      "Epoch 506/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5542 - val_loss: 0.6033\n",
      "Epoch 507/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5543 - val_loss: 0.6034\n",
      "Epoch 508/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5542 - val_loss: 0.6033\n",
      "Epoch 509/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5544 - val_loss: 0.6036\n",
      "Epoch 510/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5543 - val_loss: 0.6034\n",
      "Epoch 511/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5542 - val_loss: 0.6034\n",
      "Epoch 512/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5542 - val_loss: 0.6033\n",
      "Epoch 513/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5542 - val_loss: 0.6033\n",
      "Epoch 514/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5542 - val_loss: 0.6033\n",
      "Epoch 515/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5543 - val_loss: 0.6033\n",
      "Epoch 516/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5544 - val_loss: 0.6033\n",
      "Epoch 517/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5542 - val_loss: 0.6034\n",
      "Epoch 518/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5543 - val_loss: 0.6035\n",
      "Epoch 519/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5543 - val_loss: 0.6033\n",
      "Epoch 520/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5542 - val_loss: 0.6033\n",
      "Epoch 521/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5542 - val_loss: 0.6033\n",
      "Epoch 522/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5542 - val_loss: 0.6033\n",
      "Epoch 523/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5542 - val_loss: 0.6032\n",
      "Epoch 524/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5542 - val_loss: 0.6032\n",
      "Epoch 525/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5542 - val_loss: 0.6033\n",
      "Epoch 526/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5542 - val_loss: 0.6033\n",
      "Epoch 527/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5542 - val_loss: 0.6033\n",
      "Epoch 528/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5542 - val_loss: 0.6032\n",
      "Epoch 529/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5542 - val_loss: 0.6032\n",
      "Epoch 530/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5542 - val_loss: 0.6033\n",
      "Epoch 531/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5542 - val_loss: 0.6033\n",
      "Epoch 532/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5542 - val_loss: 0.6032\n",
      "Epoch 533/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5542 - val_loss: 0.6033\n",
      "Epoch 534/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5542 - val_loss: 0.6033\n",
      "Epoch 535/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5543 - val_loss: 0.6034\n",
      "Epoch 536/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5542 - val_loss: 0.6033\n",
      "Epoch 537/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5542 - val_loss: 0.6034\n",
      "Epoch 538/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5543 - val_loss: 0.6033\n",
      "Epoch 539/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5543 - val_loss: 0.6034\n",
      "Epoch 540/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5543 - val_loss: 0.6033\n",
      "Epoch 541/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5543 - val_loss: 0.6034\n",
      "Epoch 542/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5542 - val_loss: 0.6032\n",
      "Epoch 543/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5541 - val_loss: 0.6032\n",
      "Epoch 544/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6032\n",
      "Epoch 545/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5542 - val_loss: 0.6034\n",
      "Epoch 546/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5542 - val_loss: 0.6033\n",
      "Epoch 547/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5542 - val_loss: 0.6033\n",
      "Epoch 548/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5542 - val_loss: 0.6034\n",
      "Epoch 549/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5542 - val_loss: 0.6032\n",
      "Epoch 550/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6032\n",
      "Epoch 551/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6032\n",
      "Epoch 552/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6032\n",
      "Epoch 553/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5541 - val_loss: 0.6032\n",
      "Epoch 554/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5541 - val_loss: 0.6033\n",
      "Epoch 555/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5542 - val_loss: 0.6033\n",
      "Epoch 556/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5542 - val_loss: 0.6032\n",
      "Epoch 557/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5542 - val_loss: 0.6033\n",
      "Epoch 558/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5542 - val_loss: 0.6033\n",
      "Epoch 559/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5542 - val_loss: 0.6032\n",
      "Epoch 560/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5542 - val_loss: 0.6033\n",
      "Epoch 561/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5542 - val_loss: 0.6031\n",
      "Epoch 562/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5542 - val_loss: 0.6033\n",
      "Epoch 563/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5543 - val_loss: 0.6033\n",
      "Epoch 564/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5542 - val_loss: 0.6033\n",
      "Epoch 565/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6032\n",
      "Epoch 566/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5541 - val_loss: 0.6031\n",
      "Epoch 567/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6032\n",
      "Epoch 568/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5542 - val_loss: 0.6032\n",
      "Epoch 569/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5542 - val_loss: 0.6032\n",
      "Epoch 570/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5542 - val_loss: 0.6031\n",
      "Epoch 571/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5541 - val_loss: 0.6031\n",
      "Epoch 572/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6031\n",
      "Epoch 573/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6032\n",
      "Epoch 574/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5542 - val_loss: 0.6033\n",
      "Epoch 575/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5542 - val_loss: 0.6032\n",
      "Epoch 576/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5542 - val_loss: 0.6031\n",
      "Epoch 577/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6033\n",
      "Epoch 578/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5541 - val_loss: 0.6032\n",
      "Epoch 579/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6032\n",
      "Epoch 580/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5542 - val_loss: 0.6032\n",
      "Epoch 581/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5541 - val_loss: 0.6031\n",
      "Epoch 582/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6031\n",
      "Epoch 583/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6031\n",
      "Epoch 584/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6031\n",
      "Epoch 585/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5541 - val_loss: 0.6032\n",
      "Epoch 586/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6032\n",
      "Epoch 587/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5542 - val_loss: 0.6032\n",
      "Epoch 588/1000\n",
      "1770/1770 [==============================] - 0s 12us/step - loss: 0.5541 - val_loss: 0.6032\n",
      "Epoch 589/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5542 - val_loss: 0.6031\n",
      "Epoch 590/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6031\n",
      "Epoch 591/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6032\n",
      "Epoch 592/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6031\n",
      "Epoch 593/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5541 - val_loss: 0.6031\n",
      "Epoch 594/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6031\n",
      "Epoch 595/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5541 - val_loss: 0.6031\n",
      "Epoch 596/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6032\n",
      "Epoch 597/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6032\n",
      "Epoch 598/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5542 - val_loss: 0.6033\n",
      "Epoch 599/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6032\n",
      "Epoch 600/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5542 - val_loss: 0.6033\n",
      "Epoch 601/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6031\n",
      "Epoch 602/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5541 - val_loss: 0.6031\n",
      "Epoch 603/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6031\n",
      "Epoch 604/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6031\n",
      "Epoch 605/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6031\n",
      "Epoch 606/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6031\n",
      "Epoch 607/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6031\n",
      "Epoch 608/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5541 - val_loss: 0.6032\n",
      "Epoch 609/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6032\n",
      "Epoch 610/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5542 - val_loss: 0.6032\n",
      "Epoch 611/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6032\n",
      "Epoch 612/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6031\n",
      "Epoch 613/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5541 - val_loss: 0.6031\n",
      "Epoch 614/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5542 - val_loss: 0.6033\n",
      "Epoch 615/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5542 - val_loss: 0.6032\n",
      "Epoch 616/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5542 - val_loss: 0.6032\n",
      "Epoch 617/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6031\n",
      "Epoch 618/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6031\n",
      "Epoch 619/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6032\n",
      "Epoch 620/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6032\n",
      "Epoch 621/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 622/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5540 - val_loss: 0.6031\n",
      "Epoch 623/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5541 - val_loss: 0.6031\n",
      "Epoch 624/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6031\n",
      "Epoch 625/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5541 - val_loss: 0.6032\n",
      "Epoch 626/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6032\n",
      "Epoch 627/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5541 - val_loss: 0.6032\n",
      "Epoch 628/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6031\n",
      "Epoch 629/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 630/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6030\n",
      "Epoch 631/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5541 - val_loss: 0.6031\n",
      "Epoch 632/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6031\n",
      "Epoch 633/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6031\n",
      "Epoch 634/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6032\n",
      "Epoch 635/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6031\n",
      "Epoch 636/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5540 - val_loss: 0.6031\n",
      "Epoch 637/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5540 - val_loss: 0.6031\n",
      "Epoch 638/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6031\n",
      "Epoch 639/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6031\n",
      "Epoch 640/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6032\n",
      "Epoch 641/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6031\n",
      "Epoch 642/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6032\n",
      "Epoch 643/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5541 - val_loss: 0.6031\n",
      "Epoch 644/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5541 - val_loss: 0.6032\n",
      "Epoch 645/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6033\n",
      "Epoch 646/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5542 - val_loss: 0.6031\n",
      "Epoch 647/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6032\n",
      "Epoch 648/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5541 - val_loss: 0.6032\n",
      "Epoch 649/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5542 - val_loss: 0.6032\n",
      "Epoch 650/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5541 - val_loss: 0.6031\n",
      "Epoch 651/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5541 - val_loss: 0.6031\n",
      "Epoch 652/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5541 - val_loss: 0.6030\n",
      "Epoch 653/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 654/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5540 - val_loss: 0.6032\n",
      "Epoch 655/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6031\n",
      "Epoch 656/1000\n",
      "1770/1770 [==============================] - 0s 12us/step - loss: 0.5542 - val_loss: 0.6031\n",
      "Epoch 657/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5542 - val_loss: 0.6033\n",
      "Epoch 658/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5542 - val_loss: 0.6031\n",
      "Epoch 659/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 660/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 661/1000\n",
      "1770/1770 [==============================] - 0s 12us/step - loss: 0.5541 - val_loss: 0.6031\n",
      "Epoch 662/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6031\n",
      "Epoch 663/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6030\n",
      "Epoch 664/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 665/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 666/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 667/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 668/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 669/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 670/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 671/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5540 - val_loss: 0.6029\n",
      "Epoch 672/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6029\n",
      "Epoch 673/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 674/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 675/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6030\n",
      "Epoch 676/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 677/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 678/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 679/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 680/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 681/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 682/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 683/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 684/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 685/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 686/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5540 - val_loss: 0.6029\n",
      "Epoch 687/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 688/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 689/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 690/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6030\n",
      "Epoch 691/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6030\n",
      "Epoch 692/1000\n",
      "1770/1770 [==============================] - ETA: 0s - loss: 0.544 - 0s 10us/step - loss: 0.5539 - val_loss: 0.6030\n",
      "Epoch 693/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6030\n",
      "Epoch 694/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 695/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 696/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 697/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 698/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 699/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 700/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6031\n",
      "Epoch 701/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5541 - val_loss: 0.6031\n",
      "Epoch 702/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6029\n",
      "Epoch 703/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 704/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6030\n",
      "Epoch 705/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6030\n",
      "Epoch 706/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6030\n",
      "Epoch 707/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5540 - val_loss: 0.6031\n",
      "Epoch 708/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6029\n",
      "Epoch 709/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 710/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 711/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 712/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 713/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5540 - val_loss: 0.6031\n",
      "Epoch 714/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 715/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 716/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 717/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6031\n",
      "Epoch 718/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6031\n",
      "Epoch 719/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6029\n",
      "Epoch 720/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6030\n",
      "Epoch 721/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 722/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 723/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 724/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 725/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6031\n",
      "Epoch 726/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6030\n",
      "Epoch 727/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 728/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 729/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 730/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6031\n",
      "Epoch 731/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6031\n",
      "Epoch 732/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6030\n",
      "Epoch 733/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 734/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 735/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 736/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6030\n",
      "Epoch 737/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6030\n",
      "Epoch 738/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 739/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 740/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 741/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6029\n",
      "Epoch 742/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 743/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 744/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 745/1000\n",
      "1770/1770 [==============================] - 0s 12us/step - loss: 0.5539 - val_loss: 0.6030\n",
      "Epoch 746/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6029\n",
      "Epoch 747/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6031\n",
      "Epoch 748/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5540 - val_loss: 0.6029\n",
      "Epoch 749/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 750/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 751/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6030\n",
      "Epoch 752/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 753/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 754/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 755/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6029\n",
      "Epoch 756/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 757/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 758/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6029\n",
      "Epoch 759/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6030\n",
      "Epoch 760/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 761/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6030\n",
      "Epoch 762/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 763/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6030\n",
      "Epoch 764/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6030\n",
      "Epoch 765/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 766/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6030\n",
      "Epoch 767/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 768/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 769/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 770/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 771/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 772/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 773/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 774/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6029\n",
      "Epoch 775/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6030\n",
      "Epoch 776/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 777/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 778/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 779/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6029\n",
      "Epoch 780/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 781/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 782/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6030\n",
      "Epoch 783/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 784/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 785/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 786/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 787/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 788/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 789/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6030\n",
      "Epoch 790/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 791/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 792/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 793/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 794/1000\n",
      "1770/1770 [==============================] - 0s 12us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 795/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6029\n",
      "Epoch 796/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 797/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 798/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6030\n",
      "Epoch 799/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5541 - val_loss: 0.6029\n",
      "Epoch 800/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 801/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 802/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 803/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 804/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6030\n",
      "Epoch 805/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 806/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6030\n",
      "Epoch 807/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 808/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 809/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6030\n",
      "Epoch 810/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5540 - val_loss: 0.6029\n",
      "Epoch 811/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 812/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6030\n",
      "Epoch 813/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6029\n",
      "Epoch 814/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 815/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 816/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 817/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 818/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 819/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 820/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6029\n",
      "Epoch 821/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 822/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6030\n",
      "Epoch 823/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 824/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 825/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 826/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 827/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 828/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 829/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 830/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6029\n",
      "Epoch 831/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 832/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 833/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 834/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6031\n",
      "Epoch 835/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6029\n",
      "Epoch 836/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 837/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 838/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 839/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 840/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 841/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 842/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 843/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 844/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 845/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 846/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 847/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5538 - val_loss: 0.6029\n",
      "Epoch 848/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5538 - val_loss: 0.6028\n",
      "Epoch 849/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 850/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 851/1000\n",
      "1770/1770 [==============================] - 0s 12us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 852/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 853/1000\n",
      "1770/1770 [==============================] - 0s 12us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 854/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 855/1000\n",
      "1770/1770 [==============================] - 0s 12us/step - loss: 0.5538 - val_loss: 0.6028\n",
      "Epoch 856/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 857/1000\n",
      "1770/1770 [==============================] - 0s 12us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 858/1000\n",
      "1770/1770 [==============================] - 0s 13us/step - loss: 0.5539 - val_loss: 0.6030\n",
      "Epoch 859/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 860/1000\n",
      "1770/1770 [==============================] - 0s 12us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 861/1000\n",
      "1770/1770 [==============================] - 0s 12us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 862/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 863/1000\n",
      "1770/1770 [==============================] - 0s 12us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 864/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 865/1000\n",
      "1770/1770 [==============================] - 0s 12us/step - loss: 0.5540 - val_loss: 0.6029\n",
      "Epoch 866/1000\n",
      "1770/1770 [==============================] - 0s 12us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 867/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 868/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 869/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 870/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5538 - val_loss: 0.6029\n",
      "Epoch 871/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5538 - val_loss: 0.6028\n",
      "Epoch 872/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 873/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6030\n",
      "Epoch 874/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6030\n",
      "Epoch 875/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 876/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 877/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5538 - val_loss: 0.6028\n",
      "Epoch 878/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5538 - val_loss: 0.6028\n",
      "Epoch 879/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 880/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 881/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6030\n",
      "Epoch 882/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5540 - val_loss: 0.6029\n",
      "Epoch 883/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 884/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 885/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5538 - val_loss: 0.6028\n",
      "Epoch 886/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5538 - val_loss: 0.6028\n",
      "Epoch 887/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5538 - val_loss: 0.6028\n",
      "Epoch 888/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 889/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5538 - val_loss: 0.6028\n",
      "Epoch 890/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 891/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 892/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 893/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5538 - val_loss: 0.6028\n",
      "Epoch 894/1000\n",
      "1770/1770 [==============================] - 0s 12us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 895/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 896/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 897/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6029\n",
      "Epoch 898/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 899/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5538 - val_loss: 0.6029\n",
      "Epoch 900/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 901/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 902/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5538 - val_loss: 0.6028\n",
      "Epoch 903/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5538 - val_loss: 0.6029\n",
      "Epoch 904/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5538 - val_loss: 0.6028\n",
      "Epoch 905/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 906/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 907/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5538 - val_loss: 0.6028\n",
      "Epoch 908/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5538 - val_loss: 0.6028\n",
      "Epoch 909/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 910/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5538 - val_loss: 0.6028\n",
      "Epoch 911/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5538 - val_loss: 0.6029\n",
      "Epoch 912/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 913/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 914/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 915/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 916/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5538 - val_loss: 0.6028\n",
      "Epoch 917/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5538 - val_loss: 0.6028\n",
      "Epoch 918/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 919/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5538 - val_loss: 0.6028\n",
      "Epoch 920/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 921/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 922/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5538 - val_loss: 0.6028\n",
      "Epoch 923/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5538 - val_loss: 0.6028\n",
      "Epoch 924/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5538 - val_loss: 0.6028\n",
      "Epoch 925/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5538 - val_loss: 0.6028\n",
      "Epoch 926/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 927/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 928/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 929/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5538 - val_loss: 0.6028\n",
      "Epoch 930/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 931/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 932/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 933/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5538 - val_loss: 0.6028\n",
      "Epoch 934/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5538 - val_loss: 0.6028\n",
      "Epoch 935/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5538 - val_loss: 0.6028\n",
      "Epoch 936/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5538 - val_loss: 0.6028\n",
      "Epoch 937/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5538 - val_loss: 0.6029\n",
      "Epoch 938/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5538 - val_loss: 0.6028\n",
      "Epoch 939/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5538 - val_loss: 0.6028\n",
      "Epoch 940/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5538 - val_loss: 0.6029\n",
      "Epoch 941/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 942/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 943/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 944/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 945/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 946/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5538 - val_loss: 0.6028\n",
      "Epoch 947/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 948/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 949/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 950/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5540 - val_loss: 0.6029\n",
      "Epoch 951/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 952/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 953/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5538 - val_loss: 0.6028\n",
      "Epoch 954/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5538 - val_loss: 0.6029\n",
      "Epoch 955/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6027\n",
      "Epoch 956/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5538 - val_loss: 0.6028\n",
      "Epoch 957/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5538 - val_loss: 0.6028\n",
      "Epoch 958/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 959/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5538 - val_loss: 0.6028\n",
      "Epoch 960/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 961/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5538 - val_loss: 0.6029\n",
      "Epoch 962/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 963/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 964/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 965/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 966/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 967/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 968/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 969/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6030\n",
      "Epoch 970/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 971/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 972/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6029\n",
      "Epoch 973/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 974/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 975/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 976/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 977/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6029\n",
      "Epoch 978/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 979/1000\n",
      "1770/1770 [==============================] - 0s 12us/step - loss: 0.5540 - val_loss: 0.6028\n",
      "Epoch 980/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6031\n",
      "Epoch 981/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6028\n",
      "Epoch 982/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 983/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5538 - val_loss: 0.6028\n",
      "Epoch 984/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6030\n",
      "Epoch 985/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 986/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5538 - val_loss: 0.6028\n",
      "Epoch 987/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5538 - val_loss: 0.6028\n",
      "Epoch 988/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5538 - val_loss: 0.6029\n",
      "Epoch 989/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 990/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 991/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 992/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5538 - val_loss: 0.6028\n",
      "Epoch 993/1000\n",
      "1770/1770 [==============================] - 0s 10us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 994/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6028\n",
      "Epoch 995/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6029\n",
      "Epoch 996/1000\n",
      "1770/1770 [==============================] - 0s 12us/step - loss: 0.5540 - val_loss: 0.6029\n",
      "Epoch 997/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6029\n",
      "Epoch 998/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6030\n",
      "Epoch 999/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5540 - val_loss: 0.6031\n",
      "Epoch 1000/1000\n",
      "1770/1770 [==============================] - 0s 11us/step - loss: 0.5539 - val_loss: 0.6028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fce94181e80>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder_recon.fit(x_train_noisy, x_train,\n",
    "                      epochs=1000, batch_size=256,\n",
    "                      validation_split=0.05,\n",
    "                      verbose=1,\n",
    "                      shuffle=True,\n",
    "                      # callbacks=[TensorBoard(log_dir='./logs/autoencoder_190601-5')]\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1864 samples, validate on 30 samples\n",
      "Epoch 1/500\n",
      "1864/1864 [==============================] - 0s 148us/step - loss: 1.3700 - acc: 0.5000 - val_loss: 1.4351 - val_acc: 0.5000\n",
      "Epoch 2/500\n",
      "1864/1864 [==============================] - 0s 7us/step - loss: 1.3268 - acc: 0.5000 - val_loss: 1.3910 - val_acc: 0.5000\n",
      "Epoch 3/500\n",
      "1864/1864 [==============================] - 0s 7us/step - loss: 1.2840 - acc: 0.5000 - val_loss: 1.3462 - val_acc: 0.5000\n",
      "Epoch 4/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 1.2410 - acc: 0.5000 - val_loss: 1.3028 - val_acc: 0.5000\n",
      "Epoch 5/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 1.1992 - acc: 0.5000 - val_loss: 1.2593 - val_acc: 0.5000\n",
      "Epoch 6/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 1.1575 - acc: 0.5000 - val_loss: 1.2167 - val_acc: 0.5000\n",
      "Epoch 7/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 1.1169 - acc: 0.5000 - val_loss: 1.1755 - val_acc: 0.5000\n",
      "Epoch 8/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 1.0778 - acc: 0.5000 - val_loss: 1.1362 - val_acc: 0.5000\n",
      "Epoch 9/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 1.0405 - acc: 0.5000 - val_loss: 1.0985 - val_acc: 0.5000\n",
      "Epoch 10/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 1.0048 - acc: 0.5000 - val_loss: 1.0612 - val_acc: 0.5000\n",
      "Epoch 11/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.9698 - acc: 0.5000 - val_loss: 1.0270 - val_acc: 0.5000\n",
      "Epoch 12/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.9378 - acc: 0.5000 - val_loss: 0.9938 - val_acc: 0.5000\n",
      "Epoch 13/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.9068 - acc: 0.5000 - val_loss: 0.9630 - val_acc: 0.5000\n",
      "Epoch 14/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.8783 - acc: 0.5000 - val_loss: 0.9326 - val_acc: 0.5000\n",
      "Epoch 15/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.8502 - acc: 0.5000 - val_loss: 0.9046 - val_acc: 0.5000\n",
      "Epoch 16/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.8246 - acc: 0.5000 - val_loss: 0.8790 - val_acc: 0.5000\n",
      "Epoch 17/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.8012 - acc: 0.5000 - val_loss: 0.8544 - val_acc: 0.5000\n",
      "Epoch 18/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.7791 - acc: 0.5005 - val_loss: 0.8326 - val_acc: 0.5000\n",
      "Epoch 19/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.7595 - acc: 0.5005 - val_loss: 0.8123 - val_acc: 0.5000\n",
      "Epoch 20/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.7415 - acc: 0.5027 - val_loss: 0.7935 - val_acc: 0.5000\n",
      "Epoch 21/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.7249 - acc: 0.5032 - val_loss: 0.7764 - val_acc: 0.5000\n",
      "Epoch 22/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.7100 - acc: 0.5043 - val_loss: 0.7615 - val_acc: 0.5000\n",
      "Epoch 23/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.6972 - acc: 0.5075 - val_loss: 0.7482 - val_acc: 0.5000\n",
      "Epoch 24/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.6858 - acc: 0.5134 - val_loss: 0.7360 - val_acc: 0.5000\n",
      "Epoch 25/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.6755 - acc: 0.5193 - val_loss: 0.7251 - val_acc: 0.5000\n",
      "Epoch 26/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.6665 - acc: 0.5252 - val_loss: 0.7156 - val_acc: 0.5000\n",
      "Epoch 27/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.6587 - acc: 0.5317 - val_loss: 0.7069 - val_acc: 0.5000\n",
      "Epoch 28/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.6516 - acc: 0.5413 - val_loss: 0.6996 - val_acc: 0.4667\n",
      "Epoch 29/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.6458 - acc: 0.5563 - val_loss: 0.6931 - val_acc: 0.4667\n",
      "Epoch 30/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.6407 - acc: 0.5697 - val_loss: 0.6869 - val_acc: 0.4667\n",
      "Epoch 31/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.6360 - acc: 0.5848 - val_loss: 0.6814 - val_acc: 0.5000\n",
      "Epoch 32/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.6320 - acc: 0.5933 - val_loss: 0.6772 - val_acc: 0.5000\n",
      "Epoch 33/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.6288 - acc: 0.6035 - val_loss: 0.6729 - val_acc: 0.5000\n",
      "Epoch 34/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.6257 - acc: 0.6180 - val_loss: 0.6690 - val_acc: 0.5333\n",
      "Epoch 35/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.6230 - acc: 0.6309 - val_loss: 0.6659 - val_acc: 0.5333\n",
      "Epoch 36/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.6208 - acc: 0.6400 - val_loss: 0.6627 - val_acc: 0.5333\n",
      "Epoch 37/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.6188 - acc: 0.6518 - val_loss: 0.6604 - val_acc: 0.5333\n",
      "Epoch 38/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.6172 - acc: 0.6593 - val_loss: 0.6585 - val_acc: 0.5333\n",
      "Epoch 39/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.6158 - acc: 0.6642 - val_loss: 0.6566 - val_acc: 0.5333\n",
      "Epoch 40/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.6144 - acc: 0.6722 - val_loss: 0.6547 - val_acc: 0.5333\n",
      "Epoch 41/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.6131 - acc: 0.6829 - val_loss: 0.6526 - val_acc: 0.5333\n",
      "Epoch 42/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.6117 - acc: 0.6883 - val_loss: 0.6508 - val_acc: 0.5667\n",
      "Epoch 43/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.6104 - acc: 0.6942 - val_loss: 0.6491 - val_acc: 0.6000\n",
      "Epoch 44/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.6092 - acc: 0.6996 - val_loss: 0.6473 - val_acc: 0.6000\n",
      "Epoch 45/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.6080 - acc: 0.7103 - val_loss: 0.6458 - val_acc: 0.6000\n",
      "Epoch 46/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.6069 - acc: 0.7124 - val_loss: 0.6446 - val_acc: 0.6000\n",
      "Epoch 47/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.6057 - acc: 0.7114 - val_loss: 0.6433 - val_acc: 0.6000\n",
      "Epoch 48/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.6045 - acc: 0.7141 - val_loss: 0.6417 - val_acc: 0.5667\n",
      "Epoch 49/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.6033 - acc: 0.7200 - val_loss: 0.6404 - val_acc: 0.6000\n",
      "Epoch 50/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.6021 - acc: 0.7237 - val_loss: 0.6391 - val_acc: 0.6000\n",
      "Epoch 51/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.6009 - acc: 0.7285 - val_loss: 0.6379 - val_acc: 0.6000\n",
      "Epoch 52/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5996 - acc: 0.7291 - val_loss: 0.6366 - val_acc: 0.6000\n",
      "Epoch 53/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5984 - acc: 0.7280 - val_loss: 0.6353 - val_acc: 0.6000\n",
      "Epoch 54/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5970 - acc: 0.7302 - val_loss: 0.6336 - val_acc: 0.6333\n",
      "Epoch 55/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5958 - acc: 0.7334 - val_loss: 0.6327 - val_acc: 0.6333\n",
      "Epoch 56/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5946 - acc: 0.7355 - val_loss: 0.6314 - val_acc: 0.6333\n",
      "Epoch 57/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5933 - acc: 0.7393 - val_loss: 0.6304 - val_acc: 0.6333\n",
      "Epoch 58/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5921 - acc: 0.7393 - val_loss: 0.6290 - val_acc: 0.6333\n",
      "Epoch 59/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5909 - acc: 0.7387 - val_loss: 0.6275 - val_acc: 0.6667\n",
      "Epoch 60/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5896 - acc: 0.7462 - val_loss: 0.6258 - val_acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5883 - acc: 0.7479 - val_loss: 0.6246 - val_acc: 0.6667\n",
      "Epoch 62/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5870 - acc: 0.7479 - val_loss: 0.6233 - val_acc: 0.6667\n",
      "Epoch 63/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5858 - acc: 0.7484 - val_loss: 0.6222 - val_acc: 0.6667\n",
      "Epoch 64/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5846 - acc: 0.7516 - val_loss: 0.6206 - val_acc: 0.6667\n",
      "Epoch 65/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5834 - acc: 0.7543 - val_loss: 0.6195 - val_acc: 0.6667\n",
      "Epoch 66/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5822 - acc: 0.7532 - val_loss: 0.6179 - val_acc: 0.6667\n",
      "Epoch 67/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5809 - acc: 0.7554 - val_loss: 0.6164 - val_acc: 0.6667\n",
      "Epoch 68/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5797 - acc: 0.7543 - val_loss: 0.6150 - val_acc: 0.6667\n",
      "Epoch 69/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5786 - acc: 0.7559 - val_loss: 0.6135 - val_acc: 0.6667\n",
      "Epoch 70/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5774 - acc: 0.7613 - val_loss: 0.6126 - val_acc: 0.6667\n",
      "Epoch 71/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5761 - acc: 0.7575 - val_loss: 0.6114 - val_acc: 0.6667\n",
      "Epoch 72/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5748 - acc: 0.7586 - val_loss: 0.6107 - val_acc: 0.6667\n",
      "Epoch 73/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5736 - acc: 0.7575 - val_loss: 0.6093 - val_acc: 0.6667\n",
      "Epoch 74/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5725 - acc: 0.7570 - val_loss: 0.6079 - val_acc: 0.6667\n",
      "Epoch 75/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5713 - acc: 0.7613 - val_loss: 0.6071 - val_acc: 0.6667\n",
      "Epoch 76/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5703 - acc: 0.7580 - val_loss: 0.6056 - val_acc: 0.6667\n",
      "Epoch 77/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5691 - acc: 0.7613 - val_loss: 0.6046 - val_acc: 0.6667\n",
      "Epoch 78/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5680 - acc: 0.7602 - val_loss: 0.6031 - val_acc: 0.6667\n",
      "Epoch 79/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5669 - acc: 0.7629 - val_loss: 0.6019 - val_acc: 0.6667\n",
      "Epoch 80/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5658 - acc: 0.7607 - val_loss: 0.6005 - val_acc: 0.6667\n",
      "Epoch 81/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5647 - acc: 0.7639 - val_loss: 0.6000 - val_acc: 0.6667\n",
      "Epoch 82/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5636 - acc: 0.7618 - val_loss: 0.5992 - val_acc: 0.6667\n",
      "Epoch 83/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5625 - acc: 0.7613 - val_loss: 0.5979 - val_acc: 0.6667\n",
      "Epoch 84/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5615 - acc: 0.7656 - val_loss: 0.5968 - val_acc: 0.6667\n",
      "Epoch 85/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5605 - acc: 0.7661 - val_loss: 0.5960 - val_acc: 0.6667\n",
      "Epoch 86/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5594 - acc: 0.7650 - val_loss: 0.5947 - val_acc: 0.6667\n",
      "Epoch 87/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5583 - acc: 0.7661 - val_loss: 0.5934 - val_acc: 0.6667\n",
      "Epoch 88/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5574 - acc: 0.7698 - val_loss: 0.5922 - val_acc: 0.6667\n",
      "Epoch 89/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5563 - acc: 0.7709 - val_loss: 0.5910 - val_acc: 0.6667\n",
      "Epoch 90/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5553 - acc: 0.7715 - val_loss: 0.5903 - val_acc: 0.6667\n",
      "Epoch 91/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5545 - acc: 0.7704 - val_loss: 0.5888 - val_acc: 0.6667\n",
      "Epoch 92/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5535 - acc: 0.7720 - val_loss: 0.5880 - val_acc: 0.6667\n",
      "Epoch 93/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5525 - acc: 0.7725 - val_loss: 0.5872 - val_acc: 0.6667\n",
      "Epoch 94/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5515 - acc: 0.7725 - val_loss: 0.5863 - val_acc: 0.6667\n",
      "Epoch 95/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5505 - acc: 0.7725 - val_loss: 0.5852 - val_acc: 0.6667\n",
      "Epoch 96/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5497 - acc: 0.7736 - val_loss: 0.5840 - val_acc: 0.6667\n",
      "Epoch 97/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5488 - acc: 0.7725 - val_loss: 0.5830 - val_acc: 0.7000\n",
      "Epoch 98/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5479 - acc: 0.7736 - val_loss: 0.5827 - val_acc: 0.6667\n",
      "Epoch 99/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5470 - acc: 0.7709 - val_loss: 0.5820 - val_acc: 0.6667\n",
      "Epoch 100/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5461 - acc: 0.7709 - val_loss: 0.5812 - val_acc: 0.6667\n",
      "Epoch 101/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5454 - acc: 0.7715 - val_loss: 0.5797 - val_acc: 0.7333\n",
      "Epoch 102/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5445 - acc: 0.7736 - val_loss: 0.5794 - val_acc: 0.6667\n",
      "Epoch 103/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5437 - acc: 0.7715 - val_loss: 0.5783 - val_acc: 0.7000\n",
      "Epoch 104/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5429 - acc: 0.7758 - val_loss: 0.5776 - val_acc: 0.7000\n",
      "Epoch 105/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5420 - acc: 0.7725 - val_loss: 0.5770 - val_acc: 0.7000\n",
      "Epoch 106/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5412 - acc: 0.7715 - val_loss: 0.5759 - val_acc: 0.7333\n",
      "Epoch 107/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5405 - acc: 0.7752 - val_loss: 0.5751 - val_acc: 0.7333\n",
      "Epoch 108/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5398 - acc: 0.7709 - val_loss: 0.5747 - val_acc: 0.7000\n",
      "Epoch 109/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5390 - acc: 0.7741 - val_loss: 0.5740 - val_acc: 0.7000\n",
      "Epoch 110/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5382 - acc: 0.7736 - val_loss: 0.5736 - val_acc: 0.7000\n",
      "Epoch 111/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5374 - acc: 0.7736 - val_loss: 0.5727 - val_acc: 0.7000\n",
      "Epoch 112/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5367 - acc: 0.7736 - val_loss: 0.5720 - val_acc: 0.7000\n",
      "Epoch 113/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5360 - acc: 0.7741 - val_loss: 0.5710 - val_acc: 0.7000\n",
      "Epoch 114/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5352 - acc: 0.7725 - val_loss: 0.5701 - val_acc: 0.7333\n",
      "Epoch 115/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5344 - acc: 0.7725 - val_loss: 0.5696 - val_acc: 0.7000\n",
      "Epoch 116/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5338 - acc: 0.7704 - val_loss: 0.5689 - val_acc: 0.7333\n",
      "Epoch 117/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5331 - acc: 0.7709 - val_loss: 0.5685 - val_acc: 0.7000\n",
      "Epoch 118/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5325 - acc: 0.7731 - val_loss: 0.5678 - val_acc: 0.7000\n",
      "Epoch 119/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5318 - acc: 0.7725 - val_loss: 0.5673 - val_acc: 0.7000\n",
      "Epoch 120/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5311 - acc: 0.7752 - val_loss: 0.5657 - val_acc: 0.7000\n",
      "Epoch 121/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5305 - acc: 0.7698 - val_loss: 0.5651 - val_acc: 0.7000\n",
      "Epoch 122/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5298 - acc: 0.7698 - val_loss: 0.5646 - val_acc: 0.7000\n",
      "Epoch 123/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5292 - acc: 0.7693 - val_loss: 0.5640 - val_acc: 0.7000\n",
      "Epoch 124/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5285 - acc: 0.7715 - val_loss: 0.5631 - val_acc: 0.7000\n",
      "Epoch 125/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5281 - acc: 0.7682 - val_loss: 0.5632 - val_acc: 0.7000\n",
      "Epoch 126/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5275 - acc: 0.7720 - val_loss: 0.5624 - val_acc: 0.7000\n",
      "Epoch 127/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5268 - acc: 0.7715 - val_loss: 0.5616 - val_acc: 0.7000\n",
      "Epoch 128/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5262 - acc: 0.7693 - val_loss: 0.5606 - val_acc: 0.7000\n",
      "Epoch 129/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5257 - acc: 0.7731 - val_loss: 0.5605 - val_acc: 0.7000\n",
      "Epoch 130/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5251 - acc: 0.7709 - val_loss: 0.5597 - val_acc: 0.7000\n",
      "Epoch 131/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5246 - acc: 0.7725 - val_loss: 0.5599 - val_acc: 0.7000\n",
      "Epoch 132/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5240 - acc: 0.7704 - val_loss: 0.5586 - val_acc: 0.7000\n",
      "Epoch 133/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5235 - acc: 0.7709 - val_loss: 0.5578 - val_acc: 0.7000\n",
      "Epoch 134/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5230 - acc: 0.7715 - val_loss: 0.5578 - val_acc: 0.7000\n",
      "Epoch 135/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5225 - acc: 0.7698 - val_loss: 0.5572 - val_acc: 0.7000\n",
      "Epoch 136/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5220 - acc: 0.7725 - val_loss: 0.5573 - val_acc: 0.7000\n",
      "Epoch 137/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5215 - acc: 0.7704 - val_loss: 0.5564 - val_acc: 0.7000\n",
      "Epoch 138/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5211 - acc: 0.7709 - val_loss: 0.5565 - val_acc: 0.7000\n",
      "Epoch 139/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5205 - acc: 0.7704 - val_loss: 0.5555 - val_acc: 0.7000\n",
      "Epoch 140/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5201 - acc: 0.7736 - val_loss: 0.5547 - val_acc: 0.7000\n",
      "Epoch 141/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5196 - acc: 0.7731 - val_loss: 0.5547 - val_acc: 0.7000\n",
      "Epoch 142/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5191 - acc: 0.7725 - val_loss: 0.5540 - val_acc: 0.7000\n",
      "Epoch 143/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5186 - acc: 0.7720 - val_loss: 0.5538 - val_acc: 0.7000\n",
      "Epoch 144/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5182 - acc: 0.7715 - val_loss: 0.5528 - val_acc: 0.7000\n",
      "Epoch 145/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5178 - acc: 0.7720 - val_loss: 0.5522 - val_acc: 0.7000\n",
      "Epoch 146/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5173 - acc: 0.7736 - val_loss: 0.5516 - val_acc: 0.7000\n",
      "Epoch 147/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5169 - acc: 0.7720 - val_loss: 0.5508 - val_acc: 0.7000\n",
      "Epoch 148/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5165 - acc: 0.7704 - val_loss: 0.5508 - val_acc: 0.7000\n",
      "Epoch 149/500\n",
      "1864/1864 [==============================] - 0s 10us/step - loss: 0.5160 - acc: 0.7715 - val_loss: 0.5503 - val_acc: 0.7000\n",
      "Epoch 150/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5156 - acc: 0.7736 - val_loss: 0.5502 - val_acc: 0.7000\n",
      "Epoch 151/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5152 - acc: 0.7709 - val_loss: 0.5500 - val_acc: 0.7000\n",
      "Epoch 152/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5147 - acc: 0.7720 - val_loss: 0.5495 - val_acc: 0.7000\n",
      "Epoch 153/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5143 - acc: 0.7725 - val_loss: 0.5495 - val_acc: 0.7333\n",
      "Epoch 154/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5139 - acc: 0.7741 - val_loss: 0.5488 - val_acc: 0.7000\n",
      "Epoch 155/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5135 - acc: 0.7720 - val_loss: 0.5485 - val_acc: 0.7333\n",
      "Epoch 156/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5131 - acc: 0.7747 - val_loss: 0.5475 - val_acc: 0.7000\n",
      "Epoch 157/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5126 - acc: 0.7715 - val_loss: 0.5468 - val_acc: 0.7000\n",
      "Epoch 158/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5123 - acc: 0.7709 - val_loss: 0.5469 - val_acc: 0.7000\n",
      "Epoch 159/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5119 - acc: 0.7709 - val_loss: 0.5470 - val_acc: 0.7333\n",
      "Epoch 160/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5115 - acc: 0.7720 - val_loss: 0.5461 - val_acc: 0.7000\n",
      "Epoch 161/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5111 - acc: 0.7704 - val_loss: 0.5458 - val_acc: 0.7000\n",
      "Epoch 162/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5108 - acc: 0.7715 - val_loss: 0.5450 - val_acc: 0.7000\n",
      "Epoch 163/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5103 - acc: 0.7715 - val_loss: 0.5448 - val_acc: 0.7000\n",
      "Epoch 164/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5100 - acc: 0.7709 - val_loss: 0.5441 - val_acc: 0.7000\n",
      "Epoch 165/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5095 - acc: 0.7709 - val_loss: 0.5435 - val_acc: 0.7000\n",
      "Epoch 166/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5092 - acc: 0.7704 - val_loss: 0.5430 - val_acc: 0.7000\n",
      "Epoch 167/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5089 - acc: 0.7709 - val_loss: 0.5434 - val_acc: 0.7000\n",
      "Epoch 168/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5085 - acc: 0.7715 - val_loss: 0.5430 - val_acc: 0.7000\n",
      "Epoch 169/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5081 - acc: 0.7704 - val_loss: 0.5434 - val_acc: 0.7333\n",
      "Epoch 170/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5078 - acc: 0.7720 - val_loss: 0.5437 - val_acc: 0.7333\n",
      "Epoch 171/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5075 - acc: 0.7725 - val_loss: 0.5426 - val_acc: 0.7333\n",
      "Epoch 172/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5071 - acc: 0.7720 - val_loss: 0.5422 - val_acc: 0.7333\n",
      "Epoch 173/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5069 - acc: 0.7709 - val_loss: 0.5421 - val_acc: 0.7333\n",
      "Epoch 174/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5066 - acc: 0.7704 - val_loss: 0.5416 - val_acc: 0.7333\n",
      "Epoch 175/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5063 - acc: 0.7709 - val_loss: 0.5411 - val_acc: 0.7333\n",
      "Epoch 176/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5060 - acc: 0.7704 - val_loss: 0.5404 - val_acc: 0.7000\n",
      "Epoch 177/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5058 - acc: 0.7704 - val_loss: 0.5399 - val_acc: 0.7000\n",
      "Epoch 178/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5055 - acc: 0.7720 - val_loss: 0.5396 - val_acc: 0.7000\n",
      "Epoch 179/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5052 - acc: 0.7720 - val_loss: 0.5392 - val_acc: 0.7000\n",
      "Epoch 180/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5050 - acc: 0.7725 - val_loss: 0.5391 - val_acc: 0.7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5046 - acc: 0.7704 - val_loss: 0.5387 - val_acc: 0.7000\n",
      "Epoch 182/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5046 - acc: 0.7720 - val_loss: 0.5384 - val_acc: 0.7000\n",
      "Epoch 183/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5042 - acc: 0.7720 - val_loss: 0.5380 - val_acc: 0.7000\n",
      "Epoch 184/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5039 - acc: 0.7709 - val_loss: 0.5383 - val_acc: 0.7000\n",
      "Epoch 185/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5036 - acc: 0.7715 - val_loss: 0.5378 - val_acc: 0.7000\n",
      "Epoch 186/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5034 - acc: 0.7709 - val_loss: 0.5376 - val_acc: 0.7000\n",
      "Epoch 187/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5031 - acc: 0.7715 - val_loss: 0.5378 - val_acc: 0.7333\n",
      "Epoch 188/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5028 - acc: 0.7720 - val_loss: 0.5371 - val_acc: 0.7000\n",
      "Epoch 189/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5026 - acc: 0.7720 - val_loss: 0.5366 - val_acc: 0.7000\n",
      "Epoch 190/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5023 - acc: 0.7715 - val_loss: 0.5365 - val_acc: 0.7000\n",
      "Epoch 191/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5022 - acc: 0.7725 - val_loss: 0.5365 - val_acc: 0.7000\n",
      "Epoch 192/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5019 - acc: 0.7704 - val_loss: 0.5361 - val_acc: 0.7000\n",
      "Epoch 193/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5017 - acc: 0.7704 - val_loss: 0.5362 - val_acc: 0.7333\n",
      "Epoch 194/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.5014 - acc: 0.7715 - val_loss: 0.5359 - val_acc: 0.7333\n",
      "Epoch 195/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5011 - acc: 0.7715 - val_loss: 0.5357 - val_acc: 0.7333\n",
      "Epoch 196/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5008 - acc: 0.7709 - val_loss: 0.5360 - val_acc: 0.7333\n",
      "Epoch 197/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5008 - acc: 0.7715 - val_loss: 0.5361 - val_acc: 0.7333\n",
      "Epoch 198/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5004 - acc: 0.7741 - val_loss: 0.5353 - val_acc: 0.7333\n",
      "Epoch 199/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.5002 - acc: 0.7709 - val_loss: 0.5352 - val_acc: 0.7333\n",
      "Epoch 200/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4999 - acc: 0.7715 - val_loss: 0.5353 - val_acc: 0.7333\n",
      "Epoch 201/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4997 - acc: 0.7725 - val_loss: 0.5344 - val_acc: 0.7333\n",
      "Epoch 202/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4995 - acc: 0.7704 - val_loss: 0.5345 - val_acc: 0.7333\n",
      "Epoch 203/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4993 - acc: 0.7720 - val_loss: 0.5342 - val_acc: 0.7333\n",
      "Epoch 204/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4990 - acc: 0.7720 - val_loss: 0.5338 - val_acc: 0.7333\n",
      "Epoch 205/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4988 - acc: 0.7725 - val_loss: 0.5338 - val_acc: 0.7333\n",
      "Epoch 206/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4986 - acc: 0.7715 - val_loss: 0.5339 - val_acc: 0.7333\n",
      "Epoch 207/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4985 - acc: 0.7731 - val_loss: 0.5335 - val_acc: 0.7333\n",
      "Epoch 208/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4983 - acc: 0.7704 - val_loss: 0.5334 - val_acc: 0.7333\n",
      "Epoch 209/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4980 - acc: 0.7715 - val_loss: 0.5329 - val_acc: 0.7333\n",
      "Epoch 210/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4978 - acc: 0.7715 - val_loss: 0.5326 - val_acc: 0.7333\n",
      "Epoch 211/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4977 - acc: 0.7715 - val_loss: 0.5327 - val_acc: 0.7333\n",
      "Epoch 212/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4974 - acc: 0.7715 - val_loss: 0.5329 - val_acc: 0.7333\n",
      "Epoch 213/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4972 - acc: 0.7725 - val_loss: 0.5327 - val_acc: 0.7333\n",
      "Epoch 214/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4970 - acc: 0.7736 - val_loss: 0.5324 - val_acc: 0.7333\n",
      "Epoch 215/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4968 - acc: 0.7725 - val_loss: 0.5322 - val_acc: 0.7333\n",
      "Epoch 216/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4966 - acc: 0.7731 - val_loss: 0.5325 - val_acc: 0.7333\n",
      "Epoch 217/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4964 - acc: 0.7731 - val_loss: 0.5320 - val_acc: 0.7333\n",
      "Epoch 218/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4962 - acc: 0.7731 - val_loss: 0.5311 - val_acc: 0.7333\n",
      "Epoch 219/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4961 - acc: 0.7709 - val_loss: 0.5310 - val_acc: 0.7333\n",
      "Epoch 220/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4958 - acc: 0.7720 - val_loss: 0.5305 - val_acc: 0.7333\n",
      "Epoch 221/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4956 - acc: 0.7715 - val_loss: 0.5307 - val_acc: 0.7333\n",
      "Epoch 222/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4956 - acc: 0.7725 - val_loss: 0.5309 - val_acc: 0.7333\n",
      "Epoch 223/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4953 - acc: 0.7715 - val_loss: 0.5306 - val_acc: 0.7333\n",
      "Epoch 224/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4951 - acc: 0.7731 - val_loss: 0.5302 - val_acc: 0.7333\n",
      "Epoch 225/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4950 - acc: 0.7720 - val_loss: 0.5301 - val_acc: 0.7333\n",
      "Epoch 226/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4947 - acc: 0.7720 - val_loss: 0.5304 - val_acc: 0.7333\n",
      "Epoch 227/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4946 - acc: 0.7736 - val_loss: 0.5296 - val_acc: 0.7333\n",
      "Epoch 228/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4944 - acc: 0.7720 - val_loss: 0.5293 - val_acc: 0.7333\n",
      "Epoch 229/500\n",
      "1864/1864 [==============================] - 0s 10us/step - loss: 0.4942 - acc: 0.7709 - val_loss: 0.5292 - val_acc: 0.7333\n",
      "Epoch 230/500\n",
      "1864/1864 [==============================] - 0s 10us/step - loss: 0.4941 - acc: 0.7698 - val_loss: 0.5298 - val_acc: 0.7333\n",
      "Epoch 231/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4940 - acc: 0.7720 - val_loss: 0.5302 - val_acc: 0.7333\n",
      "Epoch 232/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4938 - acc: 0.7725 - val_loss: 0.5298 - val_acc: 0.7333\n",
      "Epoch 233/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4937 - acc: 0.7720 - val_loss: 0.5297 - val_acc: 0.7333\n",
      "Epoch 234/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4934 - acc: 0.7731 - val_loss: 0.5289 - val_acc: 0.7333\n",
      "Epoch 235/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4933 - acc: 0.7731 - val_loss: 0.5285 - val_acc: 0.7333\n",
      "Epoch 236/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4931 - acc: 0.7725 - val_loss: 0.5284 - val_acc: 0.7333\n",
      "Epoch 237/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4929 - acc: 0.7709 - val_loss: 0.5285 - val_acc: 0.7333\n",
      "Epoch 238/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4929 - acc: 0.7709 - val_loss: 0.5285 - val_acc: 0.7333\n",
      "Epoch 239/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4927 - acc: 0.7720 - val_loss: 0.5286 - val_acc: 0.7333\n",
      "Epoch 240/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4925 - acc: 0.7704 - val_loss: 0.5281 - val_acc: 0.7333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4923 - acc: 0.7720 - val_loss: 0.5283 - val_acc: 0.7333\n",
      "Epoch 242/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4922 - acc: 0.7715 - val_loss: 0.5279 - val_acc: 0.7333\n",
      "Epoch 243/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4920 - acc: 0.7709 - val_loss: 0.5275 - val_acc: 0.7333\n",
      "Epoch 244/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4919 - acc: 0.7715 - val_loss: 0.5273 - val_acc: 0.7333\n",
      "Epoch 245/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4917 - acc: 0.7709 - val_loss: 0.5271 - val_acc: 0.7333\n",
      "Epoch 246/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4917 - acc: 0.7704 - val_loss: 0.5272 - val_acc: 0.7333\n",
      "Epoch 247/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4914 - acc: 0.7715 - val_loss: 0.5272 - val_acc: 0.7333\n",
      "Epoch 248/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4913 - acc: 0.7715 - val_loss: 0.5267 - val_acc: 0.7333\n",
      "Epoch 249/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4912 - acc: 0.7693 - val_loss: 0.5262 - val_acc: 0.7333\n",
      "Epoch 250/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4911 - acc: 0.7682 - val_loss: 0.5272 - val_acc: 0.7333\n",
      "Epoch 251/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4909 - acc: 0.7709 - val_loss: 0.5277 - val_acc: 0.7333\n",
      "Epoch 252/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4908 - acc: 0.7715 - val_loss: 0.5270 - val_acc: 0.7333\n",
      "Epoch 253/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4907 - acc: 0.7736 - val_loss: 0.5269 - val_acc: 0.7333\n",
      "Epoch 254/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4905 - acc: 0.7731 - val_loss: 0.5266 - val_acc: 0.7333\n",
      "Epoch 255/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4904 - acc: 0.7698 - val_loss: 0.5269 - val_acc: 0.7333\n",
      "Epoch 256/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4902 - acc: 0.7709 - val_loss: 0.5275 - val_acc: 0.7333\n",
      "Epoch 257/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4902 - acc: 0.7731 - val_loss: 0.5268 - val_acc: 0.7333\n",
      "Epoch 258/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4900 - acc: 0.7725 - val_loss: 0.5271 - val_acc: 0.7333\n",
      "Epoch 259/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4899 - acc: 0.7725 - val_loss: 0.5264 - val_acc: 0.7333\n",
      "Epoch 260/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4898 - acc: 0.7725 - val_loss: 0.5259 - val_acc: 0.7333\n",
      "Epoch 261/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4897 - acc: 0.7698 - val_loss: 0.5261 - val_acc: 0.7333\n",
      "Epoch 262/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4895 - acc: 0.7688 - val_loss: 0.5263 - val_acc: 0.7333\n",
      "Epoch 263/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4894 - acc: 0.7731 - val_loss: 0.5255 - val_acc: 0.7333\n",
      "Epoch 264/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4894 - acc: 0.7688 - val_loss: 0.5259 - val_acc: 0.7333\n",
      "Epoch 265/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4892 - acc: 0.7709 - val_loss: 0.5256 - val_acc: 0.7333\n",
      "Epoch 266/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4892 - acc: 0.7715 - val_loss: 0.5254 - val_acc: 0.7333\n",
      "Epoch 267/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4890 - acc: 0.7693 - val_loss: 0.5253 - val_acc: 0.7333\n",
      "Epoch 268/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4889 - acc: 0.7709 - val_loss: 0.5254 - val_acc: 0.7333\n",
      "Epoch 269/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4888 - acc: 0.7715 - val_loss: 0.5251 - val_acc: 0.7333\n",
      "Epoch 270/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4887 - acc: 0.7704 - val_loss: 0.5251 - val_acc: 0.7333\n",
      "Epoch 271/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4886 - acc: 0.7704 - val_loss: 0.5257 - val_acc: 0.7333\n",
      "Epoch 272/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4886 - acc: 0.7698 - val_loss: 0.5262 - val_acc: 0.7333\n",
      "Epoch 273/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4885 - acc: 0.7741 - val_loss: 0.5258 - val_acc: 0.7333\n",
      "Epoch 274/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4883 - acc: 0.7731 - val_loss: 0.5254 - val_acc: 0.7333\n",
      "Epoch 275/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4883 - acc: 0.7709 - val_loss: 0.5248 - val_acc: 0.7333\n",
      "Epoch 276/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4883 - acc: 0.7704 - val_loss: 0.5244 - val_acc: 0.7333\n",
      "Epoch 277/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4880 - acc: 0.7693 - val_loss: 0.5247 - val_acc: 0.7333\n",
      "Epoch 278/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4880 - acc: 0.7688 - val_loss: 0.5250 - val_acc: 0.7333\n",
      "Epoch 279/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4879 - acc: 0.7709 - val_loss: 0.5243 - val_acc: 0.7333\n",
      "Epoch 280/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4878 - acc: 0.7682 - val_loss: 0.5246 - val_acc: 0.7333\n",
      "Epoch 281/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4877 - acc: 0.7698 - val_loss: 0.5243 - val_acc: 0.7333\n",
      "Epoch 282/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4876 - acc: 0.7709 - val_loss: 0.5238 - val_acc: 0.7333\n",
      "Epoch 283/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4875 - acc: 0.7693 - val_loss: 0.5241 - val_acc: 0.7333\n",
      "Epoch 284/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4874 - acc: 0.7704 - val_loss: 0.5241 - val_acc: 0.7333\n",
      "Epoch 285/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4873 - acc: 0.7677 - val_loss: 0.5247 - val_acc: 0.7333\n",
      "Epoch 286/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4872 - acc: 0.7709 - val_loss: 0.5249 - val_acc: 0.7333\n",
      "Epoch 287/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4871 - acc: 0.7709 - val_loss: 0.5247 - val_acc: 0.7333\n",
      "Epoch 288/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4871 - acc: 0.7720 - val_loss: 0.5248 - val_acc: 0.7333\n",
      "Epoch 289/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4870 - acc: 0.7709 - val_loss: 0.5245 - val_acc: 0.7333\n",
      "Epoch 290/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4870 - acc: 0.7720 - val_loss: 0.5242 - val_acc: 0.7333\n",
      "Epoch 291/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4868 - acc: 0.7704 - val_loss: 0.5244 - val_acc: 0.7333\n",
      "Epoch 292/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4867 - acc: 0.7709 - val_loss: 0.5246 - val_acc: 0.7333\n",
      "Epoch 293/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4866 - acc: 0.7715 - val_loss: 0.5240 - val_acc: 0.7333\n",
      "Epoch 294/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4866 - acc: 0.7715 - val_loss: 0.5239 - val_acc: 0.7333\n",
      "Epoch 295/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4866 - acc: 0.7693 - val_loss: 0.5246 - val_acc: 0.7333\n",
      "Epoch 296/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4864 - acc: 0.7709 - val_loss: 0.5243 - val_acc: 0.7333\n",
      "Epoch 297/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4863 - acc: 0.7715 - val_loss: 0.5238 - val_acc: 0.7333\n",
      "Epoch 298/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4862 - acc: 0.7698 - val_loss: 0.5242 - val_acc: 0.7333\n",
      "Epoch 299/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4862 - acc: 0.7715 - val_loss: 0.5243 - val_acc: 0.7333\n",
      "Epoch 300/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4861 - acc: 0.7720 - val_loss: 0.5242 - val_acc: 0.7333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4861 - acc: 0.7709 - val_loss: 0.5232 - val_acc: 0.7333\n",
      "Epoch 302/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4859 - acc: 0.7693 - val_loss: 0.5234 - val_acc: 0.7333\n",
      "Epoch 303/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4859 - acc: 0.7688 - val_loss: 0.5236 - val_acc: 0.7333\n",
      "Epoch 304/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4858 - acc: 0.7715 - val_loss: 0.5233 - val_acc: 0.7333\n",
      "Epoch 305/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4857 - acc: 0.7688 - val_loss: 0.5229 - val_acc: 0.7333\n",
      "Epoch 306/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4857 - acc: 0.7688 - val_loss: 0.5230 - val_acc: 0.7333\n",
      "Epoch 307/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4856 - acc: 0.7698 - val_loss: 0.5229 - val_acc: 0.7333\n",
      "Epoch 308/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4855 - acc: 0.7693 - val_loss: 0.5234 - val_acc: 0.7333\n",
      "Epoch 309/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4854 - acc: 0.7698 - val_loss: 0.5236 - val_acc: 0.7333\n",
      "Epoch 310/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4854 - acc: 0.7682 - val_loss: 0.5234 - val_acc: 0.7333\n",
      "Epoch 311/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4855 - acc: 0.7682 - val_loss: 0.5234 - val_acc: 0.7333\n",
      "Epoch 312/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4852 - acc: 0.7709 - val_loss: 0.5233 - val_acc: 0.7333\n",
      "Epoch 313/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4851 - acc: 0.7677 - val_loss: 0.5234 - val_acc: 0.7333\n",
      "Epoch 314/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4851 - acc: 0.7715 - val_loss: 0.5233 - val_acc: 0.7333\n",
      "Epoch 315/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4850 - acc: 0.7709 - val_loss: 0.5229 - val_acc: 0.7333\n",
      "Epoch 316/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4849 - acc: 0.7672 - val_loss: 0.5229 - val_acc: 0.7333\n",
      "Epoch 317/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4848 - acc: 0.7693 - val_loss: 0.5229 - val_acc: 0.7333\n",
      "Epoch 318/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4848 - acc: 0.7693 - val_loss: 0.5226 - val_acc: 0.7333\n",
      "Epoch 319/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4847 - acc: 0.7688 - val_loss: 0.5230 - val_acc: 0.7333\n",
      "Epoch 320/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4846 - acc: 0.7682 - val_loss: 0.5228 - val_acc: 0.7333\n",
      "Epoch 321/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4847 - acc: 0.7688 - val_loss: 0.5233 - val_acc: 0.7333\n",
      "Epoch 322/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4845 - acc: 0.7698 - val_loss: 0.5236 - val_acc: 0.7333\n",
      "Epoch 323/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4845 - acc: 0.7693 - val_loss: 0.5229 - val_acc: 0.7333\n",
      "Epoch 324/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4844 - acc: 0.7709 - val_loss: 0.5223 - val_acc: 0.7333\n",
      "Epoch 325/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4844 - acc: 0.7688 - val_loss: 0.5228 - val_acc: 0.7333\n",
      "Epoch 326/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4842 - acc: 0.7698 - val_loss: 0.5230 - val_acc: 0.7333\n",
      "Epoch 327/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4842 - acc: 0.7720 - val_loss: 0.5230 - val_acc: 0.7333\n",
      "Epoch 328/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4842 - acc: 0.7688 - val_loss: 0.5237 - val_acc: 0.7333\n",
      "Epoch 329/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4840 - acc: 0.7715 - val_loss: 0.5231 - val_acc: 0.7333\n",
      "Epoch 330/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4840 - acc: 0.7704 - val_loss: 0.5233 - val_acc: 0.7333\n",
      "Epoch 331/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4839 - acc: 0.7704 - val_loss: 0.5235 - val_acc: 0.7333\n",
      "Epoch 332/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4839 - acc: 0.7715 - val_loss: 0.5232 - val_acc: 0.7333\n",
      "Epoch 333/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4838 - acc: 0.7704 - val_loss: 0.5232 - val_acc: 0.7333\n",
      "Epoch 334/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4838 - acc: 0.7704 - val_loss: 0.5226 - val_acc: 0.7333\n",
      "Epoch 335/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4837 - acc: 0.7709 - val_loss: 0.5233 - val_acc: 0.7333\n",
      "Epoch 336/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4836 - acc: 0.7698 - val_loss: 0.5233 - val_acc: 0.7333\n",
      "Epoch 337/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4836 - acc: 0.7704 - val_loss: 0.5229 - val_acc: 0.7333\n",
      "Epoch 338/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4836 - acc: 0.7693 - val_loss: 0.5225 - val_acc: 0.7333\n",
      "Epoch 339/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4834 - acc: 0.7693 - val_loss: 0.5220 - val_acc: 0.7333\n",
      "Epoch 340/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4834 - acc: 0.7693 - val_loss: 0.5226 - val_acc: 0.7333\n",
      "Epoch 341/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4834 - acc: 0.7704 - val_loss: 0.5222 - val_acc: 0.7333\n",
      "Epoch 342/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4833 - acc: 0.7704 - val_loss: 0.5220 - val_acc: 0.7333\n",
      "Epoch 343/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4833 - acc: 0.7704 - val_loss: 0.5216 - val_acc: 0.7333\n",
      "Epoch 344/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4833 - acc: 0.7677 - val_loss: 0.5220 - val_acc: 0.7333\n",
      "Epoch 345/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4831 - acc: 0.7698 - val_loss: 0.5220 - val_acc: 0.7333\n",
      "Epoch 346/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4831 - acc: 0.7677 - val_loss: 0.5225 - val_acc: 0.7333\n",
      "Epoch 347/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4830 - acc: 0.7693 - val_loss: 0.5224 - val_acc: 0.7333\n",
      "Epoch 348/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4829 - acc: 0.7688 - val_loss: 0.5228 - val_acc: 0.7333\n",
      "Epoch 349/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4829 - acc: 0.7698 - val_loss: 0.5233 - val_acc: 0.7333\n",
      "Epoch 350/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4828 - acc: 0.7709 - val_loss: 0.5231 - val_acc: 0.7333\n",
      "Epoch 351/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4828 - acc: 0.7709 - val_loss: 0.5234 - val_acc: 0.7333\n",
      "Epoch 352/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4828 - acc: 0.7704 - val_loss: 0.5225 - val_acc: 0.7333\n",
      "Epoch 353/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4827 - acc: 0.7704 - val_loss: 0.5223 - val_acc: 0.7333\n",
      "Epoch 354/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4827 - acc: 0.7715 - val_loss: 0.5225 - val_acc: 0.7333\n",
      "Epoch 355/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4826 - acc: 0.7704 - val_loss: 0.5229 - val_acc: 0.7333\n",
      "Epoch 356/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4826 - acc: 0.7698 - val_loss: 0.5220 - val_acc: 0.7333\n",
      "Epoch 357/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4825 - acc: 0.7661 - val_loss: 0.5227 - val_acc: 0.7333\n",
      "Epoch 358/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4825 - acc: 0.7704 - val_loss: 0.5221 - val_acc: 0.7333\n",
      "Epoch 359/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4825 - acc: 0.7677 - val_loss: 0.5225 - val_acc: 0.7333\n",
      "Epoch 360/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4825 - acc: 0.7688 - val_loss: 0.5228 - val_acc: 0.7333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4823 - acc: 0.7720 - val_loss: 0.5221 - val_acc: 0.7333\n",
      "Epoch 362/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4824 - acc: 0.7677 - val_loss: 0.5225 - val_acc: 0.7333\n",
      "Epoch 363/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4822 - acc: 0.7715 - val_loss: 0.5223 - val_acc: 0.7333\n",
      "Epoch 364/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4823 - acc: 0.7661 - val_loss: 0.5229 - val_acc: 0.7333\n",
      "Epoch 365/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4822 - acc: 0.7709 - val_loss: 0.5219 - val_acc: 0.7333\n",
      "Epoch 366/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4822 - acc: 0.7666 - val_loss: 0.5220 - val_acc: 0.7333\n",
      "Epoch 367/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4820 - acc: 0.7693 - val_loss: 0.5219 - val_acc: 0.7333\n",
      "Epoch 368/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4820 - acc: 0.7661 - val_loss: 0.5216 - val_acc: 0.7333\n",
      "Epoch 369/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4821 - acc: 0.7661 - val_loss: 0.5222 - val_acc: 0.7333\n",
      "Epoch 370/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4820 - acc: 0.7672 - val_loss: 0.5228 - val_acc: 0.7333\n",
      "Epoch 371/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4819 - acc: 0.7715 - val_loss: 0.5226 - val_acc: 0.7333\n",
      "Epoch 372/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4819 - acc: 0.7709 - val_loss: 0.5224 - val_acc: 0.7333\n",
      "Epoch 373/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4819 - acc: 0.7709 - val_loss: 0.5227 - val_acc: 0.7333\n",
      "Epoch 374/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4818 - acc: 0.7715 - val_loss: 0.5228 - val_acc: 0.7333\n",
      "Epoch 375/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4819 - acc: 0.7704 - val_loss: 0.5233 - val_acc: 0.7333\n",
      "Epoch 376/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4817 - acc: 0.7715 - val_loss: 0.5232 - val_acc: 0.7333\n",
      "Epoch 377/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4818 - acc: 0.7709 - val_loss: 0.5233 - val_acc: 0.7333\n",
      "Epoch 378/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4817 - acc: 0.7704 - val_loss: 0.5233 - val_acc: 0.7333\n",
      "Epoch 379/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4816 - acc: 0.7709 - val_loss: 0.5231 - val_acc: 0.7333\n",
      "Epoch 380/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4816 - acc: 0.7698 - val_loss: 0.5226 - val_acc: 0.7333\n",
      "Epoch 381/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4815 - acc: 0.7709 - val_loss: 0.5222 - val_acc: 0.7333\n",
      "Epoch 382/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4815 - acc: 0.7650 - val_loss: 0.5228 - val_acc: 0.7333\n",
      "Epoch 383/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4814 - acc: 0.7704 - val_loss: 0.5222 - val_acc: 0.7333\n",
      "Epoch 384/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4814 - acc: 0.7693 - val_loss: 0.5219 - val_acc: 0.7333\n",
      "Epoch 385/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4814 - acc: 0.7656 - val_loss: 0.5227 - val_acc: 0.7333\n",
      "Epoch 386/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4813 - acc: 0.7698 - val_loss: 0.5227 - val_acc: 0.7333\n",
      "Epoch 387/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4815 - acc: 0.7656 - val_loss: 0.5229 - val_acc: 0.7333\n",
      "Epoch 388/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4813 - acc: 0.7704 - val_loss: 0.5227 - val_acc: 0.7333\n",
      "Epoch 389/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4813 - acc: 0.7709 - val_loss: 0.5221 - val_acc: 0.7333\n",
      "Epoch 390/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4813 - acc: 0.7677 - val_loss: 0.5221 - val_acc: 0.7333\n",
      "Epoch 391/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4813 - acc: 0.7693 - val_loss: 0.5223 - val_acc: 0.7333\n",
      "Epoch 392/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4812 - acc: 0.7645 - val_loss: 0.5230 - val_acc: 0.7333\n",
      "Epoch 393/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4812 - acc: 0.7693 - val_loss: 0.5232 - val_acc: 0.7333\n",
      "Epoch 394/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4812 - acc: 0.7693 - val_loss: 0.5232 - val_acc: 0.7333\n",
      "Epoch 395/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4811 - acc: 0.7698 - val_loss: 0.5225 - val_acc: 0.7333\n",
      "Epoch 396/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4811 - acc: 0.7704 - val_loss: 0.5220 - val_acc: 0.7333\n",
      "Epoch 397/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4812 - acc: 0.7661 - val_loss: 0.5225 - val_acc: 0.7333\n",
      "Epoch 398/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4810 - acc: 0.7698 - val_loss: 0.5220 - val_acc: 0.7333\n",
      "Epoch 399/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4810 - acc: 0.7650 - val_loss: 0.5228 - val_acc: 0.7333\n",
      "Epoch 400/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4809 - acc: 0.7709 - val_loss: 0.5225 - val_acc: 0.7333\n",
      "Epoch 401/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4809 - acc: 0.7656 - val_loss: 0.5224 - val_acc: 0.7333\n",
      "Epoch 402/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4809 - acc: 0.7693 - val_loss: 0.5225 - val_acc: 0.7333\n",
      "Epoch 403/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4809 - acc: 0.7677 - val_loss: 0.5224 - val_acc: 0.7333\n",
      "Epoch 404/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4809 - acc: 0.7656 - val_loss: 0.5222 - val_acc: 0.7333\n",
      "Epoch 405/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4809 - acc: 0.7650 - val_loss: 0.5228 - val_acc: 0.7333\n",
      "Epoch 406/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4808 - acc: 0.7709 - val_loss: 0.5230 - val_acc: 0.7333\n",
      "Epoch 407/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4807 - acc: 0.7698 - val_loss: 0.5231 - val_acc: 0.7333\n",
      "Epoch 408/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4807 - acc: 0.7709 - val_loss: 0.5234 - val_acc: 0.7333\n",
      "Epoch 409/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4808 - acc: 0.7704 - val_loss: 0.5231 - val_acc: 0.7333\n",
      "Epoch 410/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4807 - acc: 0.7688 - val_loss: 0.5228 - val_acc: 0.7333\n",
      "Epoch 411/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4807 - acc: 0.7682 - val_loss: 0.5230 - val_acc: 0.7333\n",
      "Epoch 412/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4806 - acc: 0.7698 - val_loss: 0.5229 - val_acc: 0.7333\n",
      "Epoch 413/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4806 - acc: 0.7682 - val_loss: 0.5227 - val_acc: 0.7333\n",
      "Epoch 414/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4806 - acc: 0.7666 - val_loss: 0.5230 - val_acc: 0.7333\n",
      "Epoch 415/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4805 - acc: 0.7698 - val_loss: 0.5233 - val_acc: 0.7333\n",
      "Epoch 416/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4807 - acc: 0.7698 - val_loss: 0.5225 - val_acc: 0.7333\n",
      "Epoch 417/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4805 - acc: 0.7666 - val_loss: 0.5231 - val_acc: 0.7333\n",
      "Epoch 418/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4805 - acc: 0.7704 - val_loss: 0.5235 - val_acc: 0.7333\n",
      "Epoch 419/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4805 - acc: 0.7693 - val_loss: 0.5230 - val_acc: 0.7333\n",
      "Epoch 420/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4804 - acc: 0.7672 - val_loss: 0.5229 - val_acc: 0.7333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 421/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4804 - acc: 0.7709 - val_loss: 0.5233 - val_acc: 0.7333\n",
      "Epoch 422/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4804 - acc: 0.7709 - val_loss: 0.5228 - val_acc: 0.7333\n",
      "Epoch 423/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4803 - acc: 0.7677 - val_loss: 0.5229 - val_acc: 0.7333\n",
      "Epoch 424/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4803 - acc: 0.7677 - val_loss: 0.5235 - val_acc: 0.7333\n",
      "Epoch 425/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4803 - acc: 0.7709 - val_loss: 0.5234 - val_acc: 0.7333\n",
      "Epoch 426/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4802 - acc: 0.7698 - val_loss: 0.5231 - val_acc: 0.7333\n",
      "Epoch 427/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4802 - acc: 0.7682 - val_loss: 0.5235 - val_acc: 0.7333\n",
      "Epoch 428/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4802 - acc: 0.7704 - val_loss: 0.5232 - val_acc: 0.7333\n",
      "Epoch 429/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4802 - acc: 0.7677 - val_loss: 0.5231 - val_acc: 0.7333\n",
      "Epoch 430/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4801 - acc: 0.7698 - val_loss: 0.5226 - val_acc: 0.7333\n",
      "Epoch 431/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4801 - acc: 0.7666 - val_loss: 0.5232 - val_acc: 0.7333\n",
      "Epoch 432/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4801 - acc: 0.7709 - val_loss: 0.5238 - val_acc: 0.7333\n",
      "Epoch 433/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4800 - acc: 0.7709 - val_loss: 0.5229 - val_acc: 0.7333\n",
      "Epoch 434/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4801 - acc: 0.7666 - val_loss: 0.5236 - val_acc: 0.7333\n",
      "Epoch 435/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4800 - acc: 0.7704 - val_loss: 0.5232 - val_acc: 0.7333\n",
      "Epoch 436/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4800 - acc: 0.7677 - val_loss: 0.5239 - val_acc: 0.7333\n",
      "Epoch 437/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4801 - acc: 0.7709 - val_loss: 0.5238 - val_acc: 0.7333\n",
      "Epoch 438/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4800 - acc: 0.7704 - val_loss: 0.5234 - val_acc: 0.7333\n",
      "Epoch 439/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4799 - acc: 0.7704 - val_loss: 0.5233 - val_acc: 0.7333\n",
      "Epoch 440/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4799 - acc: 0.7698 - val_loss: 0.5231 - val_acc: 0.7333\n",
      "Epoch 441/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4800 - acc: 0.7682 - val_loss: 0.5228 - val_acc: 0.7333\n",
      "Epoch 442/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4799 - acc: 0.7666 - val_loss: 0.5228 - val_acc: 0.7333\n",
      "Epoch 443/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4798 - acc: 0.7688 - val_loss: 0.5229 - val_acc: 0.7333\n",
      "Epoch 444/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4798 - acc: 0.7656 - val_loss: 0.5236 - val_acc: 0.7333\n",
      "Epoch 445/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4798 - acc: 0.7709 - val_loss: 0.5232 - val_acc: 0.7333\n",
      "Epoch 446/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4797 - acc: 0.7698 - val_loss: 0.5231 - val_acc: 0.7333\n",
      "Epoch 447/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4798 - acc: 0.7704 - val_loss: 0.5235 - val_acc: 0.7333\n",
      "Epoch 448/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4797 - acc: 0.7709 - val_loss: 0.5237 - val_acc: 0.7333\n",
      "Epoch 449/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4797 - acc: 0.7709 - val_loss: 0.5242 - val_acc: 0.7333\n",
      "Epoch 450/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4797 - acc: 0.7704 - val_loss: 0.5241 - val_acc: 0.7333\n",
      "Epoch 451/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4797 - acc: 0.7709 - val_loss: 0.5238 - val_acc: 0.7333\n",
      "Epoch 452/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4797 - acc: 0.7709 - val_loss: 0.5236 - val_acc: 0.7333\n",
      "Epoch 453/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4797 - acc: 0.7698 - val_loss: 0.5235 - val_acc: 0.7333\n",
      "Epoch 454/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4796 - acc: 0.7688 - val_loss: 0.5235 - val_acc: 0.7333\n",
      "Epoch 455/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4795 - acc: 0.7709 - val_loss: 0.5232 - val_acc: 0.7333\n",
      "Epoch 456/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4795 - acc: 0.7666 - val_loss: 0.5233 - val_acc: 0.7333\n",
      "Epoch 457/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4796 - acc: 0.7693 - val_loss: 0.5235 - val_acc: 0.7333\n",
      "Epoch 458/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4795 - acc: 0.7661 - val_loss: 0.5240 - val_acc: 0.7333\n",
      "Epoch 459/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4795 - acc: 0.7715 - val_loss: 0.5240 - val_acc: 0.7333\n",
      "Epoch 460/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4795 - acc: 0.7704 - val_loss: 0.5235 - val_acc: 0.7333\n",
      "Epoch 461/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4794 - acc: 0.7666 - val_loss: 0.5232 - val_acc: 0.7667\n",
      "Epoch 462/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4795 - acc: 0.7661 - val_loss: 0.5237 - val_acc: 0.7333\n",
      "Epoch 463/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4794 - acc: 0.7677 - val_loss: 0.5238 - val_acc: 0.7333\n",
      "Epoch 464/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4793 - acc: 0.7677 - val_loss: 0.5238 - val_acc: 0.7333\n",
      "Epoch 465/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4794 - acc: 0.7688 - val_loss: 0.5237 - val_acc: 0.7333\n",
      "Epoch 466/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4793 - acc: 0.7682 - val_loss: 0.5233 - val_acc: 0.7667\n",
      "Epoch 467/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4793 - acc: 0.7661 - val_loss: 0.5236 - val_acc: 0.7667\n",
      "Epoch 468/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4793 - acc: 0.7656 - val_loss: 0.5238 - val_acc: 0.7333\n",
      "Epoch 469/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4792 - acc: 0.7672 - val_loss: 0.5242 - val_acc: 0.7333\n",
      "Epoch 470/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4793 - acc: 0.7682 - val_loss: 0.5239 - val_acc: 0.7333\n",
      "Epoch 471/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4792 - acc: 0.7677 - val_loss: 0.5238 - val_acc: 0.7667\n",
      "Epoch 472/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4791 - acc: 0.7666 - val_loss: 0.5239 - val_acc: 0.7333\n",
      "Epoch 473/500\n",
      "1864/1864 [==============================] - 0s 10us/step - loss: 0.4792 - acc: 0.7688 - val_loss: 0.5234 - val_acc: 0.7667\n",
      "Epoch 474/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4791 - acc: 0.7639 - val_loss: 0.5239 - val_acc: 0.7333\n",
      "Epoch 475/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4792 - acc: 0.7682 - val_loss: 0.5240 - val_acc: 0.7333\n",
      "Epoch 476/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4791 - acc: 0.7677 - val_loss: 0.5237 - val_acc: 0.7667\n",
      "Epoch 477/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4791 - acc: 0.7666 - val_loss: 0.5234 - val_acc: 0.7667\n",
      "Epoch 478/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4790 - acc: 0.7656 - val_loss: 0.5241 - val_acc: 0.7333\n",
      "Epoch 479/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4790 - acc: 0.7672 - val_loss: 0.5241 - val_acc: 0.7333\n",
      "Epoch 480/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4790 - acc: 0.7682 - val_loss: 0.5244 - val_acc: 0.7333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4790 - acc: 0.7693 - val_loss: 0.5243 - val_acc: 0.7333\n",
      "Epoch 482/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4790 - acc: 0.7682 - val_loss: 0.5239 - val_acc: 0.7667\n",
      "Epoch 483/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4790 - acc: 0.7677 - val_loss: 0.5234 - val_acc: 0.7667\n",
      "Epoch 484/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4790 - acc: 0.7639 - val_loss: 0.5240 - val_acc: 0.7667\n",
      "Epoch 485/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4789 - acc: 0.7672 - val_loss: 0.5242 - val_acc: 0.7667\n",
      "Epoch 486/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4789 - acc: 0.7682 - val_loss: 0.5237 - val_acc: 0.7667\n",
      "Epoch 487/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4789 - acc: 0.7645 - val_loss: 0.5236 - val_acc: 0.7667\n",
      "Epoch 488/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4790 - acc: 0.7634 - val_loss: 0.5245 - val_acc: 0.7333\n",
      "Epoch 489/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4789 - acc: 0.7709 - val_loss: 0.5240 - val_acc: 0.7667\n",
      "Epoch 490/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4789 - acc: 0.7656 - val_loss: 0.5243 - val_acc: 0.7667\n",
      "Epoch 491/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4788 - acc: 0.7688 - val_loss: 0.5240 - val_acc: 0.7667\n",
      "Epoch 492/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4790 - acc: 0.7677 - val_loss: 0.5242 - val_acc: 0.7667\n",
      "Epoch 493/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4788 - acc: 0.7666 - val_loss: 0.5246 - val_acc: 0.7333\n",
      "Epoch 494/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4788 - acc: 0.7704 - val_loss: 0.5240 - val_acc: 0.7667\n",
      "Epoch 495/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4787 - acc: 0.7666 - val_loss: 0.5241 - val_acc: 0.7667\n",
      "Epoch 496/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4787 - acc: 0.7661 - val_loss: 0.5246 - val_acc: 0.7667\n",
      "Epoch 497/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4787 - acc: 0.7709 - val_loss: 0.5244 - val_acc: 0.7667\n",
      "Epoch 498/500\n",
      "1864/1864 [==============================] - 0s 9us/step - loss: 0.4787 - acc: 0.7677 - val_loss: 0.5249 - val_acc: 0.7333\n",
      "Epoch 499/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4787 - acc: 0.7704 - val_loss: 0.5241 - val_acc: 0.7667\n",
      "Epoch 500/500\n",
      "1864/1864 [==============================] - 0s 8us/step - loss: 0.4788 - acc: 0.7661 - val_loss: 0.5243 - val_acc: 0.7667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fce832429b0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classifier\n",
    "classifier = Dense(2, activation='softmax')(hidden_2)\n",
    "\n",
    "autoencoder_classify = Model(input_data, classifier)\n",
    "for layer in autoencoder_classify.layers[:-1]:\n",
    "    layer.trainable=False\n",
    "\n",
    "autoencoder_classify.compile(optimizer='adadelta', loss='categorical_crossentropy',\n",
    "                            metrics=['accuracy'])\n",
    "\n",
    "autoencoder_classify.fit(x_train, y_labels_train,\n",
    "                      epochs=500, batch_size=256,\n",
    "                      shuffle=True,\n",
    "                      validation_data=(x_test_classifier, y_labels_test),\n",
    "                      #callbacks=[TensorBoard(log_dir='./logs/autoencoder_cl_190601-5')]\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1]\n",
      "0.7666666666666667\n"
     ]
    }
   ],
   "source": [
    "predicted = autoencoder_classify.predict(x_test_classifier)\n",
    "prediction_result = np.argmax(predicted, axis=1)\n",
    "print(prediction_result)\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_test_classifier, prediction_result)\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "print(auc_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fce80d10f28>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc_keras))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<keras.engine.input_layer.InputLayer object at 0x7fce94187be0>, <keras.layers.core.Dense object at 0x7fce94187c18>, <keras.layers.core.Dense object at 0x7fce94187898>, <keras.layers.core.Dense object at 0x7fce82fa0198>]\n"
     ]
    }
   ],
   "source": [
    "print(autoencoder_classify.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_recon.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_classify.layers[-1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Weights Colormap - 1')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fce80c86630>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "weight, bias = autoencoder_recon.layers[1].get_weights()\n",
    "\n",
    "plt.imshow(weight, cmap=plt.cm.autumn)\n",
    "plt.colorbar()\n",
    "plt.title('Weights Colormap - 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x7fce8033b198>,\n",
       "  <matplotlib.axis.XTick at 0x7fce80233240>,\n",
       "  <matplotlib.axis.XTick at 0x7fce8033b320>,\n",
       "  <matplotlib.axis.XTick at 0x7fce801f9ef0>,\n",
       "  <matplotlib.axis.XTick at 0x7fce80180588>,\n",
       "  <matplotlib.axis.XTick at 0x7fce80180be0>,\n",
       "  <matplotlib.axis.XTick at 0x7fce801852b0>,\n",
       "  <matplotlib.axis.XTick at 0x7fce80185940>],\n",
       " <a list of 8 Text xticklabel objects>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fce8040e908>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "weight_avg = np.average(weight, axis=1)\n",
    "plt.plot(range(1,9), weight_avg)\n",
    "plt.title('Weights Average - 1')\n",
    "plt.xticks(range(1,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weight = pd.DataFrame(weight, \n",
    "                         columns=['Feature 1','Feature 2','Feature 3', 'Feature 4',\n",
    "                                 'Feature 5','Feature 6', 'Feature 7'])\n",
    "\n",
    "df_weight.to_csv(\"./Weights_sigmoid_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.08309639 0.2017416  0.53755784 ... 0.26892006 0.13284165 0.7969153 ]\n",
      " [0.089535   0.2132976  0.7834557  ... 0.12539375 0.05533299 0.41297263]\n",
      " [0.12417826 0.26960486 0.73942655 ... 0.1593855  0.07446209 0.4347534 ]\n",
      " ...\n",
      " [0.40076244 0.58103806 0.53181195 ... 0.35224992 0.2124205  0.46843272]\n",
      " [0.2481029  0.45457193 0.44092247 ... 0.34503597 0.19681504 0.62167406]\n",
      " [0.4122715  0.61372685 0.33915403 ... 0.44327825 0.2911452  0.5968534 ]]\n",
      "      Contrast  Dissimilarity   Entropy  SumAverage  AutoCorrelation  \\\n",
      "0     0.060793       0.191241  0.508526    0.835470         0.747732   \n",
      "1     0.078852       0.185523  0.771363    0.424021         0.387763   \n",
      "2     0.166583       0.338598  0.671784    0.514270         0.369265   \n",
      "3     0.134599       0.289457  0.800151    0.421111         0.314318   \n",
      "4     0.163204       0.316215  0.858170    0.362923         0.275476   \n",
      "5     0.159482       0.294970  0.833486    0.319728         0.263842   \n",
      "6     0.142493       0.271786  0.835539    0.320574         0.268154   \n",
      "7     0.162361       0.315648  0.821376    0.364281         0.294706   \n",
      "8     0.079082       0.199192  0.815874    0.236465         0.160414   \n",
      "9     0.024976       0.094667  0.810382    0.103185         0.058975   \n",
      "10    0.218712       0.360935  0.656305    0.321504         0.271266   \n",
      "11    0.215487       0.407549  0.529382    0.592759         0.471366   \n",
      "12    0.131281       0.300418  0.667384    0.566679         0.452530   \n",
      "13    0.085469       0.223105  0.763238    0.455680         0.385185   \n",
      "14    0.100969       0.226698  0.769005    0.512903         0.451656   \n",
      "15    0.200468       0.396152  0.463638    0.694984         0.583093   \n",
      "16    0.100262       0.242284  0.685847    0.541492         0.449677   \n",
      "17    0.206314       0.396414  0.443256    0.711122         0.606940   \n",
      "18    0.059145       0.154835  0.762214    0.774734         0.695073   \n",
      "19    0.072964       0.132203  0.814470    0.782176         0.736818   \n",
      "20    0.061664       0.126099  0.842145    0.794030         0.732271   \n",
      "21    0.077908       0.176816  0.829278    0.627206         0.568222   \n",
      "22    0.060870       0.169655  0.728071    0.725733         0.627280   \n",
      "23    0.051295       0.172444  0.518110    0.862707         0.796527   \n",
      "24    0.106934       0.241507  0.677044    0.729305         0.642892   \n",
      "25    0.070374       0.207230  0.630192    0.742794         0.645432   \n",
      "26    0.048139       0.153067  0.775058    0.620342         0.517077   \n",
      "27    0.022700       0.090867  0.797040    0.179122         0.083151   \n",
      "28    0.140301       0.307815  0.435768    0.679693         0.545653   \n",
      "29    0.117832       0.255125  0.540630    0.797700         0.715573   \n",
      "...        ...            ...       ...         ...              ...   \n",
      "1863  0.320167       0.560097  0.224640    0.830943         0.722543   \n",
      "1864  0.558019       0.738067  0.328852    0.701583         0.559934   \n",
      "1865  0.632253       0.796315  0.279471    0.692461         0.546799   \n",
      "1866  0.320167       0.560097  0.224640    0.830943         0.722543   \n",
      "1867  0.558019       0.738067  0.328852    0.701583         0.559934   \n",
      "1868  0.413155       0.615203  0.224640    0.817389         0.703244   \n",
      "1869  0.298029       0.502339  0.141789    0.830299         0.728137   \n",
      "1870  0.309187       0.553827  0.264617    0.832961         0.725259   \n",
      "1871  0.610209       0.787585  0.411064    0.585411         0.440942   \n",
      "1872  0.508455       0.706965  0.315000    0.734983         0.600835   \n",
      "1873  0.452527       0.667712  0.346604    0.726140         0.593117   \n",
      "1874  0.287039       0.514776  0.465126    0.619096         0.497693   \n",
      "1875  0.156627       0.336048  0.444624    0.807244         0.700805   \n",
      "1876  0.194575       0.331983  0.647693    0.725029         0.629589   \n",
      "1877  0.221151       0.430924  0.407661    0.779383         0.675230   \n",
      "1878  0.179501       0.279494  0.655683    0.734811         0.654624   \n",
      "1880  0.506276       0.668610  0.466219    0.478653         0.359584   \n",
      "1881  0.818841       0.833995  0.410033    0.598224         0.450145   \n",
      "1882  0.423464       0.638060  0.442920    0.508853         0.397298   \n",
      "1883  0.449417       0.658689  0.419703    0.594301         0.469426   \n",
      "1884  0.364009       0.595114  0.322186    0.702402         0.567476   \n",
      "1885  0.108537       0.268683  0.417732    0.831226         0.741880   \n",
      "1886  0.159741       0.324771  0.605787    0.628002         0.539149   \n",
      "1887  0.139633       0.293974  0.590361    0.708155         0.609556   \n",
      "1888  0.108694       0.269008  0.443256    0.818751         0.732373   \n",
      "1889  0.306935       0.404837  0.446267    0.794822         0.713238   \n",
      "1890  0.346677       0.527088  0.545751    0.513068         0.411747   \n",
      "1891  0.399146       0.536537  0.603625    0.520881         0.431136   \n",
      "1892  0.312944       0.479218  0.444624    0.680166         0.580513   \n",
      "1893  0.444710       0.678709  0.283577    0.683001         0.553483   \n",
      "\n",
      "      Skewness  Kurtosis  MeanValue  \n",
      "0     0.268454  0.129176   0.809935  \n",
      "1     0.161510  0.057792   0.401535  \n",
      "2     0.050808  0.010014   0.492886  \n",
      "3     0.079445  0.045560   0.411479  \n",
      "4     0.181040  0.114735   0.352080  \n",
      "5     0.200623  0.086659   0.314821  \n",
      "6     0.164073  0.070733   0.310854  \n",
      "7     0.141555  0.064682   0.348936  \n",
      "8     0.108641  0.039298   0.225617  \n",
      "9     0.212032  0.117523   0.092850  \n",
      "10    0.307882  0.167638   0.301859  \n",
      "11    0.334066  0.222054   0.544037  \n",
      "12    0.344002  0.245590   0.545506  \n",
      "13    0.153778  0.079277   0.430955  \n",
      "14    0.176705  0.064791   0.490926  \n",
      "15    0.363580  0.231104   0.676617  \n",
      "16    0.299532  0.185505   0.505491  \n",
      "17    0.322188  0.189297   0.665259  \n",
      "18    0.106261  0.022343   0.758524  \n",
      "19    0.136966  0.030201   0.761228  \n",
      "20    0.138680  0.033756   0.773271  \n",
      "21    0.188514  0.059769   0.599285  \n",
      "22    0.166483  0.075643   0.696191  \n",
      "23    0.661178  0.568231   0.841329  \n",
      "24    0.185415  0.069068   0.684824  \n",
      "25    0.339835  0.224346   0.711489  \n",
      "26    0.115889  0.045678   0.597149  \n",
      "27    0.031770  0.005009   0.174761  \n",
      "28    0.168123  0.053369   0.646215  \n",
      "29    0.328588  0.177856   0.761273  \n",
      "...        ...       ...        ...  \n",
      "1863  0.374045  0.167740   0.787020  \n",
      "1864  0.627655  0.505224   0.629860  \n",
      "1865  0.395604  0.208320   0.622857  \n",
      "1866  0.374045  0.167740   0.787020  \n",
      "1867  0.627655  0.505224   0.629860  \n",
      "1868  0.492547  0.294777   0.774250  \n",
      "1869  0.346725  0.128502   0.781665  \n",
      "1870  0.575739  0.429014   0.788915  \n",
      "1871  0.295764  0.145571   0.504832  \n",
      "1872  0.602409  0.475090   0.663517  \n",
      "1873  0.530573  0.396947   0.665700  \n",
      "1874  0.368438  0.232848   0.552249  \n",
      "1875  0.410834  0.275418   0.807559  \n",
      "1876  0.158791  0.055215   0.675698  \n",
      "1877  0.561328  0.434162   0.734490  \n",
      "1878  0.194957  0.084162   0.693122  \n",
      "1880  0.379937  0.254102   0.412040  \n",
      "1881  0.454912  0.308965   0.552007  \n",
      "1882  0.310646  0.170752   0.446923  \n",
      "1883  0.265178  0.118484   0.524606  \n",
      "1884  0.321496  0.159043   0.635092  \n",
      "1885  0.352181  0.201639   0.790453  \n",
      "1886  0.325142  0.206001   0.587882  \n",
      "1887  0.226980  0.119472   0.672100  \n",
      "1888  0.314477  0.156936   0.776604  \n",
      "1889  0.319001  0.171715   0.730112  \n",
      "1890  0.359828  0.223460   0.451675  \n",
      "1891  0.426208  0.261866   0.461701  \n",
      "1892  0.310646  0.170752   0.613353  \n",
      "1893  0.316607  0.123765   0.630581  \n",
      "\n",
      "[1864 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "decoded_all = autoencoder_recon.predict(x_train)\n",
    "print(decoded_all)\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
